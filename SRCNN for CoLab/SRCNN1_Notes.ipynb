{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SRCNN1_Notes.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"tPqasU9ydp5o","colab_type":"code","colab":{}},"source":["!unzip input_images.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wozfse1UeF3m","colab_type":"code","colab":{}},"source":["# option 2 for images\n","#!unzip -uq \"/content/drive/My Drive/PATH_TO_ZIP\" -d \"/content/drive/My Drive/Colab Notebooks/Image-Super-Resolution/input_images.zip\"\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"I_0RQp9Mfe8A","colab_type":"code","colab":{}},"source":["'''\n","## os library is used to assign filepath locations too\n","import os\n","os.chdir('./drive/My Drive/Colab Notebooks/Image-Super-Resolution')\n","'''"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s90E5-DbffrM","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"colab_type":"code","id":"NmQ6YZlhfh6a","colab":{"base_uri":"https://localhost:8080/","height":150},"outputId":"11b90bce-e5b1-4949-9b63-c312c19f980c","executionInfo":{"status":"error","timestamp":1566239924545,"user_tz":300,"elapsed":500,"user":{"displayName":"Chris H","photoUrl":"https://lh5.googleusercontent.com/-nSgQPDHt3xI/AAAAAAAAAAI/AAAAAAAAAQQ/2R6OZokGpgg/s64/photo.jpg","userId":"06776436809075546973"}}},"source":["'''\n","Colab google: uploading images in multiple subdirectories: If you would like to upload images (or files) in multiples subdirectories by using Colab google, please follow the following steps: - I'll suppose that your images(files) are split into 3 subdirectories (train, validate, test) in the main directory called (dataDir): 1- Zip the folder (dataDir) to (dataDir.zip) 2- Write this code in a Colab cell:\n","\n","from google.colab import files\n","uploaded = files.upload()\n","3- Press on 'Choose Files' and upload (dataDir.zip) from your PC to the Colab Now the (dataDir.zip) is uploaded to your google drive! 4- Let us unzip the folder(dataDir.zip) to a folder called (data) by writing this simple code:\n","\n","import zipfile\n","import io\n","data = zipfile.ZipFile(io.BytesIO(uploaded['dataDir.zip']), 'r')\n","data.extractall()\n","5- Now everything is ready, let us check that by printing content of (data) folder:\n","\n","data.printdir()\n","6- Then to read the images, count them, split them and play around them, please write the following code:\n","\n","train_data_dir = 'data/training'  \n","validation_data_dir = 'data/validation'  \n","test_data_dir = 'data/test' \n","target_names = [item for item in os.listdir(train_data_dir) if os.path.isdir(os.path.join(train_data_dir, item))]\n","nb_train_samples = sum([len(files) for _, _, files in os.walk(train_data_dir)])  \n","nb_validation_samples = sum([len(files) for _, _, files in os.walk(validation_data_dir)])\n","nb_test_samples = sum([len(files) for _, _, files in os.walk(test_data_dir)])\n","total_nb_samples = nb_train_samples + nb_validation_samples + nb_test_samples\n","\n","nb_classes = len(target_names)      # number of output classes\n","\n","print('Training a CNN Multi-Classifier Model ......')\n","print('\\n - names of classes: ', target_names, '\\n - # of classes: ', nb_classes)\n","print(' - # of trained samples: ', nb_train_samples, '\\n - # of validation samples: ', nb_validation_samples,\n","      '\\n - # of test samples: ', nb_test_samples,\n","       '\\n - total # of samples: ', total_nb_samples, '\\n - train ratio:', round(nb_train_samples/total_nb_samples*100, 2),\n","      '\\n - validation ratio:', round(nb_validation_samples/total_nb_samples*100, 2),\n","      '\\n - test ratio:', round(nb_test_samples/total_nb_samples*100, 2),\n","     ' %', '\\n - # of epochs: ', epochs, '\\n - batch size: ', batch_size)\n","7- That is it! Enjoy!\n","'''\n"],"execution_count":1,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-80514ede9ab4>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Colab google: uploading images in multiple subdirectories: If you would like to upload images (or files) in multiples subdirectories by using Colab google, please follow the following steps: - I'll suppose that your images(files) are split into 3 subdirectories (train, validate, test) in the main directory called (dataDir): 1- Zip the folder (dataDir) to (dataDir.zip) 2- Write this code in a Colab cell:\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","metadata":{"id":"5ctWkYvGBQg7","colab_type":"code","outputId":"de1ed229-fba6-4680-a523-6512a00e791d","executionInfo":{"status":"ok","timestamp":1565991917880,"user_tz":300,"elapsed":3079,"user":{"displayName":"Chris H","photoUrl":"https://lh5.googleusercontent.com/-nSgQPDHt3xI/AAAAAAAAAAI/AAAAAAAAAQQ/2R6OZokGpgg/s64/photo.jpg","userId":"06776436809075546973"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["!pip install -U scipy==1.2.0"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already up-to-date: scipy==1.2.0 in /usr/local/lib/python3.6/dist-packages (1.2.0)\n","Requirement already satisfied, skipping upgrade: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.2.0) (1.16.4)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hajwzNN8BfGV","colab_type":"code","outputId":"8e5dec11-9fad-4247-f9e5-7cc9c382a5eb","executionInfo":{"status":"ok","timestamp":1565991923643,"user_tz":300,"elapsed":228,"user":{"displayName":"Chris H","photoUrl":"https://lh5.googleusercontent.com/-nSgQPDHt3xI/AAAAAAAAAAI/AAAAAAAAAQQ/2R6OZokGpgg/s64/photo.jpg","userId":"06776436809075546973"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","root_dir = \"/content/drive/My Drive/\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2hV4_G_8RdHD","colab_type":"code","outputId":"80c8f0d7-720c-4a2e-c151-76055985b305","executionInfo":{"status":"ok","timestamp":1565991926755,"user_tz":300,"elapsed":894,"user":{"displayName":"Chris H","photoUrl":"https://lh5.googleusercontent.com/-nSgQPDHt3xI/AAAAAAAAAAI/AAAAAAAAAQQ/2R6OZokGpgg/s64/photo.jpg","userId":"06776436809075546973"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["!cd drive/My Drive/Colab Notebooks/Image-Super-Resolution"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/bin/bash: line 0: cd: too many arguments\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EZPT2bu7Hmo4","colab_type":"code","outputId":"b6939958-673e-4ded-8241-269e213ab09a","executionInfo":{"status":"ok","timestamp":1565991929656,"user_tz":300,"elapsed":637,"user":{"displayName":"Chris H","photoUrl":"https://lh5.googleusercontent.com/-nSgQPDHt3xI/AAAAAAAAAAI/AAAAAAAAAQQ/2R6OZokGpgg/s64/photo.jpg","userId":"06776436809075546973"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["!pwd"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/Image-Super-Resolution\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yDWfmtnaBH1U","colab_type":"code","colab":{}},"source":["import numpy as np\n","from scipy.misc import imsave, imread, imresize\n","from sklearn.feature_extraction.image import reconstruct_from_patches_2d, extract_patches_2d\n","from scipy.ndimage.filters import gaussian_filter\n","\n","from keras import backend as K\n","\n","import os\n","import time\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SBJgRCCjC2h3","colab_type":"code","colab":{}},"source":["'''\n","_image_scale_multiplier is a special variable which is used to alter image size.\n","\n","The default image size is 32x32. If a true upscaling model is used, then the input image size is 16x16,\n","which not offer adequate training samples.\n","'''\n","_image_scale_multiplier = 1\n","\n","img_size = 128 * _image_scale_multiplier\n","stride = 64 * _image_scale_multiplier\n","\n","assert (img_size ** 2) % (stride ** 2) == 0, \"Number of images generated from strided subsample of the image needs to be \\n\" \\\n","                                             \"a positive integer. Change stride such that : \\n\" \\\n","                                             \"(img_size ** 2) / (stride ** 2) is a positive integer.\"\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IXDuAJUbC2mS","colab_type":"code","colab":{}},"source":["input_path = r\"D:\\Yue\\Documents\\Datasets\\train2014\\train2014\\\\\" # r\"input_images/\"\n","validation_path = r\"val_images/\"\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hwWDRSA_C8LN","colab_type":"code","colab":{}},"source":["\n","validation_set5_path = validation_path + r\"set5/\"\n","validation_set14_path = validation_path + r\"set14/\"\n","\n","base_dataset_dir = r\"/content/drive/My Drive/Colab Notebooks/Image-Super-Resolution\" + r\"/Dataset/\"\n","\n","output_path = base_dataset_dir + \"train_images/train/\"\n","validation_output_path = base_dataset_dir + r\"train_images/validation/\"\n","\n","if not os.path.exists(output_path):\n","    os.makedirs(output_path)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MSP-PRfFC8Q4","colab_type":"code","colab":{}},"source":["\n","def transform_images_temp(directory, output_directory, scaling_factor=2, max_nb_images=-1, true_upscale=False,\n","                          id_advance=0):\n","    index = 1\n","\n","    if not os.path.exists(output_directory + \"X/\"):\n","        os.makedirs(output_directory + \"X/\")\n","\n","    if not os.path.exists(output_directory + \"y/\"):\n","        os.makedirs(output_directory + \"y/\")\n","\n","    # For each image in input_images directory\n","    nb_images = len([name for name in os.listdir(directory)])\n","\n","    if max_nb_images != -1:\n","        print(\"Transforming %d images.\" % max_nb_images)\n","    else:\n","        assert max_nb_images <= nb_images, \"Max number of images must be less than number of images in path\"\n","        print(\"Transforming %d images.\" % (nb_images))\n","\n","    if nb_images == 0:\n","        print(\"Extract the training images or images from imageset_91.zip (found in the releases of the project) \"\n","              \"into a directory with the name 'input_images'\")\n","        print(\"Extract the validation images or images from set5_validation.zip (found in the releases of the project) \"\n","              \"into a directory with the name 'val_images'\")\n","        exit()\n","\n","    for file in os.listdir(directory):\n","        img = imread(directory + file, mode='RGB')\n","\n","        # Resize to 256 x 256\n","        img = imresize(img, (img_size, img_size))\n","\n","        # Create patches\n","        hr_patch_size = 64\n","        lr_patch_size = 32\n","        nb_hr_images = (img_size ** 2) // (stride ** 2)\n","\n","        hr_samples = np.empty((nb_hr_images, hr_patch_size, hr_patch_size, 3))\n","\n","        image_subsample_iterator = subimage_generator(img, stride, hr_patch_size, nb_hr_images)\n","\n","        stride_range = np.sqrt(nb_hr_images).astype(int)\n","\n","        i = 0\n","        for j in range(stride_range):\n","            for k in range(stride_range):\n","                hr_samples[i, :, :, :] = next(image_subsample_iterator)\n","                i += 1\n","\n","\n","        t1 = time.time()\n","        # Create nb_hr_images 'X' and 'Y' sub-images of size hr_patch_size for each patch\n","        for i in range(nb_hr_images):\n","            ip = hr_samples[i]\n","            # Save ground truth image X\n","            imsave(output_directory + \"/y/\" + \"%d_%d.png\" % (index + id_advance, i + 1), ip)\n","\n","            # Apply Gaussian Blur to Y\n","            #op = gaussian_filter(ip, sigma=0.5)\n","\n","            # Subsample by scaling factor to Y\n","            op = imresize(ip, (lr_patch_size, lr_patch_size), interp='bicubic')\n","\n","            if not true_upscale:\n","                # Upscale by scaling factor to Y\n","                op = imresize(op, (hr_patch_size, hr_patch_size), interp='bicubic')\n","\n","            # Save Y\n","            imsave(output_directory + \"/X/\" + \"%d_%d.png\" % (index + id_advance, id_advance + i + 1), op)\n","\n","        print(\"Finished image %d in time %0.2f seconds. (%s)\" % (index + id_advance, time.time() - t1, file))\n","        index += 1\n","\n","        if max_nb_images > 0 and index >= max_nb_images:\n","            print(\"Transformed maximum number of images. \")\n","            break\n","\n","    print(\"Images transformed. Saved at directory : %s\" % (output_directory))\n","\n","\n","def image_count():\n","    return len([name for name in os.listdir(output_path + \"X/\")])\n","\n","\n","def val_image_count():\n","    return len([name for name in os.listdir(validation_output_path + \"X/\")])\n","\n","\n","def subimage_generator(img, stride, patch_size, nb_hr_images):\n","    for _ in range(nb_hr_images):\n","        for x in range(0, img_size, stride):\n","            for y in range(0, img_size, stride):\n","                subimage = img[x : x + patch_size, y : y + patch_size, :]\n","\n","                yield subimage\n","\n","\n","def make_patches(x, scale, patch_size, upscale=True, verbose=1):\n","    '''x shape: (num_channels, rows, cols)'''\n","    height, width = x.shape[:2]\n","    if upscale: x = imresize(x, (height * scale, width * scale))\n","    patches = extract_patches_2d(x, (patch_size, patch_size))\n","    return patches\n","\n","\n","def combine_patches(in_patches, out_shape, scale):\n","    '''Reconstruct an image from these `patches`'''\n","    recon = reconstruct_from_patches_2d(in_patches, out_shape)\n","    return recon\n","\n","def image_generator(directory, scale_factor=2, target_shape=None, channels=3, small_train_images=False, shuffle=True,\n","                    batch_size=32, nb_inputs=1, seed=None):\n","    if not target_shape:\n","        if small_train_images:\n","            if K.image_dim_ordering() == \"th\":\n","                image_shape = (channels, 16 * _image_scale_multiplier, 16 * _image_scale_multiplier)\n","                y_image_shape = (channels, 16 * scale_factor * _image_scale_multiplier,\n","                                 16 * scale_factor * _image_scale_multiplier)\n","            else:\n","                # image_shape = (16 * _image_scale_multiplier, 16 * _image_scale_multiplier, channels)\n","                # y_image_shape = (16 * scale_factor * _image_scale_multiplier,\n","                #                  16 * scale_factor * _image_scale_multiplier, channels)\n","                image_shape = (32 * _image_scale_multiplier, 32 * _image_scale_multiplier, channels)\n","                y_image_shape = (32 * scale_factor * _image_scale_multiplier,\n","                                 32 * scale_factor * _image_scale_multiplier, channels)\n","        else:\n","            if K.image_dim_ordering() == \"th\":\n","                image_shape = (channels, 32 * scale_factor * _image_scale_multiplier, 32 * scale_factor * _image_scale_multiplier)\n","                y_image_shape = image_shape\n","            else:\n","                image_shape = (32 * scale_factor * _image_scale_multiplier, 32 * scale_factor * _image_scale_multiplier,\n","                               channels)\n","                y_image_shape = image_shape\n","    else:\n","        if small_train_images:\n","            if K.image_dim_ordering() == \"th\":\n","                y_image_shape = (3,) + target_shape\n","\n","                target_shape = (target_shape[0] * _image_scale_multiplier // scale_factor,\n","                                target_shape[1] * _image_scale_multiplier // scale_factor)\n","                image_shape = (3,) + target_shape\n","            else:\n","                y_image_shape = target_shape + (channels,)\n","\n","                target_shape = (target_shape[0] * _image_scale_multiplier // scale_factor,\n","                                target_shape[1] * _image_scale_multiplier // scale_factor)\n","                image_shape = target_shape + (channels,)\n","        else:\n","            if K.image_dim_ordering() == \"th\":\n","                image_shape = (channels,) + target_shape\n","                y_image_shape = image_shape\n","            else:\n","                image_shape = target_shape + (channels,)\n","                y_image_shape = image_shape\n","\n","    file_names = [f for f in sorted(os.listdir(directory + \"X/\"))]\n","    X_filenames = [os.path.join(directory, \"X\", f) for f in file_names]\n","    y_filenames = [os.path.join(directory, \"y\", f) for f in file_names]\n","\n","    nb_images = len(file_names)\n","    print(\"Found %d images.\" % nb_images)\n","\n","    index_generator = _index_generator(nb_images, batch_size, shuffle, seed)\n","\n","    while 1:\n","        index_array, current_index, current_batch_size = next(index_generator)\n","\n","        batch_x = np.zeros((current_batch_size,) + image_shape)\n","        batch_y = np.zeros((current_batch_size,) + y_image_shape)\n","\n","        for i, j in enumerate(index_array):\n","            x_fn = X_filenames[j]\n","            img = imread(x_fn, mode='RGB')\n","            if small_train_images:\n","                img = imresize(img, (32 * _image_scale_multiplier, 32 * _image_scale_multiplier))\n","            img = img.astype('float32') / 255.\n","\n","            if K.image_dim_ordering() == \"th\":\n","                batch_x[i] = img.transpose((2, 0, 1))\n","            else:\n","                batch_x[i] = img\n","\n","            y_fn = y_filenames[j]\n","            img = imread(y_fn, mode=\"RGB\")\n","            img = img.astype('float32') / 255.\n","\n","            if K.image_dim_ordering() == \"th\":\n","                batch_y[i] = img.transpose((2, 0, 1))\n","            else:\n","                batch_y[i] = img\n","\n","        if nb_inputs == 1:\n","            yield (batch_x, batch_y)\n","        else:\n","            batch_x = [batch_x for i in range(nb_inputs)]\n","            yield batch_x, batch_y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dYJIvu3wC8OH","colab_type":"code","colab":{}},"source":["def _index_generator(N, batch_size=32, shuffle=True, seed=None):\n","    batch_index = 0\n","    total_batches_seen = 0\n","\n","    while 1:\n","        if seed is not None:\n","            np.random.seed(seed + total_batches_seen)\n","\n","        if batch_index == 0:\n","            index_array = np.arange(N)\n","            if shuffle:\n","                index_array = np.random.permutation(N)\n","\n","        current_index = (batch_index * batch_size) % N\n","\n","        if N >= current_index + batch_size:\n","            current_batch_size = batch_size\n","            batch_index += 1\n","        else:\n","            current_batch_size = N - current_index\n","            batch_index = 0\n","        total_batches_seen += 1\n","\n","        yield (index_array[current_index: current_index + current_batch_size],\n","               current_index, current_batch_size)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2DkW-YOYD5xq","colab_type":"code","colab":{}},"source":["def smooth_gan_labels(y):\n","    assert len(y.shape) == 2, \"Needs to be a binary class\"\n","    y = np.asarray(y, dtype='int')\n","    Y = np.zeros(y.shape, dtype='float32')\n","\n","    for i in range(y.shape[0]):\n","        for j in range(y.shape[1]):\n","            if y[i, j] == 0:\n","                Y[i, j] = np.random.uniform(0.0, 0.3)\n","            else:\n","                Y[i, j] = np.random.uniform(0.7, 1.2)\n","\n","    return Y\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"keInINbwD5t-","colab_type":"code","outputId":"7132e063-cbb8-4592-d1ee-cd6d3b1d0388","executionInfo":{"status":"ok","timestamp":1565994133877,"user_tz":300,"elapsed":1041,"user":{"displayName":"Chris H","photoUrl":"https://lh5.googleusercontent.com/-nSgQPDHt3xI/AAAAAAAAAAI/AAAAAAAAAQQ/2R6OZokGpgg/s64/photo.jpg","userId":"06776436809075546973"}},"colab":{"base_uri":"https://localhost:8080/","height":564}},"source":["if __name__ == \"__main__\":\n","    # Transform the images once, then run the main code to scale images\n","\n","    # Change scaling factor to increase the scaling factor\n","    scaling_factor = 2\n","\n","    # Set true_upscale to True to generate smaller training images that will then be true upscaled.\n","    # Leave as false to create same size input and output images\n","    true_upscale = True\n","\n","    # transform_images_temp(input_path, output_path, scaling_factor=scaling_factor, max_nb_images=-1,\n","    #                  true_upscale=true_upscale)\n","    transform_images_temp(validation_set14_path, validation_output_path, scaling_factor=scaling_factor, max_nb_images=-1,\n","                     true_upscale=true_upscale)\n","    # transform_images_temp(validation_set14_path, validation_output_path, scaling_factor=scaling_factor, max_nb_images=-1,\n","    #                       true_upscale=true_upscale)\n","    pass\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Transforming 14 images.\n","Finished image 1 in time 0.04 seconds. (barbara.bmp)\n","Finished image 2 in time 0.06 seconds. (coastguard.bmp)\n","Finished image 3 in time 0.04 seconds. (bridge.bmp)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: DeprecationWarning: `imread` is deprecated!\n","`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n","Use ``imageio.imread`` instead.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: DeprecationWarning: `imresize` is deprecated!\n","`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n","Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: `imsave` is deprecated!\n","`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n","Use ``imageio.imwrite`` instead.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:63: DeprecationWarning: `imresize` is deprecated!\n","`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n","Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: DeprecationWarning: `imsave` is deprecated!\n","`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n","Use ``imageio.imwrite`` instead.\n"],"name":"stderr"},{"output_type":"stream","text":["Finished image 4 in time 0.06 seconds. (baboon.bmp)\n","Finished image 5 in time 0.04 seconds. (zebra.bmp)\n","Finished image 6 in time 0.05 seconds. (lenna.bmp)\n","Finished image 7 in time 0.06 seconds. (man.bmp)\n","Finished image 8 in time 0.05 seconds. (flowers.bmp)\n","Finished image 9 in time 0.06 seconds. (pepper.bmp)\n","Finished image 10 in time 0.04 seconds. (monarch.bmp)\n","Finished image 11 in time 0.06 seconds. (ppt3.bmp)\n","Finished image 12 in time 0.04 seconds. (face.bmp)\n","Finished image 13 in time 0.04 seconds. (foreman.bmp)\n","Finished image 14 in time 0.06 seconds. (comic.bmp)\n","Images transformed. Saved at directory : /content/drive/My Drive/Colab Notebooks/Image-Super-Resolution/Dataset/train_images/validation/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sHzsToBSD5qu","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-4ZfBS-jTKiq","colab_type":"code","colab":{}},"source":["!pip install opencv"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kr63KSDtS2nQ","colab_type":"code","colab":{}},"source":["!apt-get -qq install -y libsm6 libxext6 && pip install -q -U opencv-python\n","import cv2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rt1eKQkWS3GE","colab_type":"code","colab":{}},"source":["!pip install -q keras\n","import keras"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2nsma9FQS0iC","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Esr6h7SgSX1E","colab_type":"code","colab":{}},"source":["import models\n","import argparse\n","import tensorflow as tf"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0kEfKUQBS0b4","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lucqOZxPRhOr","colab_type":"code","colab":{}},"source":["import models\n","import argparse\n","import tensorflow as tf\n","\n","parser = argparse.ArgumentParser(description=\"Up-Scales an image using Image Super Resolution Model\")\n","parser.add_argument(\"imgpath\", type=str, nargs=\"+\", help=\"Path to input image\")\n","parser.add_argument(\"--model\", type=str, default=\"distilled_rnsr\", help=\"Use either image super resolution (sr), \"\n","                        \"expanded super resolution (esr), denoising auto encoder sr (dsr), \"\n","                        \"deep denoising sr (ddsr) or res net sr (rnsr)\")\n","parser.add_argument(\"--scale\", default=2, help='Scaling factor. Default = 2x')\n","parser.add_argument(\"--mode\", default=\"patch\", type=str, help='Mode of operation. Choices are \"fast\" or \"patch\"')\n","parser.add_argument(\"--save_intermediate\", dest='save', default='True', type=str,\n","                        help=\"Whether to save bilinear upscaled image\")\n","parser.add_argument(\"--suffix\", default=\"scaled\", type=str, help='Suffix of saved image')\n","parser.add_argument(\"--patch_size\", type=int, default=8, help='Patch Size')\n","\n","def strToBool(v):\n","    return v.lower() in (\"true\", \"yes\", \"t\", \"1\")\n","\n","args = parser.parse_args()\n","\n","\n","suffix = args.suffix\n","\n","model_type = str(args.model).lower()\n","if not model_type in [\"sr\", \"esr\", \"dsr\", \"ddsr\", \"rnsr\", \"distilled_rnsr\"]:\n","    raise ValueError('Model type must be either \"sr\", \"esr\", \"dsr\", '\n","                     '\"ddsr\", \"rnsr\" or \"distilled_rnsr\"')\n","\n","mode = str(args.mode).lower()\n","assert mode in ['fast', 'patch'], 'Mode of operation must be either \"fast\" or \"patch\"'\n","\n","scale_factor = int(args.scale)\n","save = strToBool(args.save)\n","\n","patch_size = int(args.patch_size)\n","assert patch_size > 0, \"Patch size must be a positive integer\"\n","\n","with tf.device('/CPU:0'):\n","    path = args.imgpath\n","    for p in path:\n","        if model_type == \"sr\":\n","            model = models.ImageSuperResolutionModel(scale_factor)\n","        elif model_type == \"esr\":\n","            model = models.ExpantionSuperResolution(scale_factor)\n","        elif model_type == \"dsr\":\n","            model = models.DenoisingAutoEncoderSR(scale_factor)\n","        elif model_type == \"ddsr\":\n","            model = models.DeepDenoiseSR(scale_factor)\n","        elif model_type == \"rnsr\":\n","            model = models.ResNetSR(scale_factor)\n","        elif model_type == \"distilled_rnsr\":\n","            model = models.DistilledResNetSR(scale_factor)\n","        else:\n","            model = models.DistilledResNetSR(scale_factor)\n","\n","        model.upscale(p, save_intermediate=save, mode=mode, patch_size=patch_size, suffix=suffix)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"P8OoifdGRmIo","colab_type":"code","colab":{}},"source":["!ls"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qaIpA5NjRsWq","colab_type":"code","colab":{}},"source":["cd drive"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mtVrmligR08X","colab_type":"code","colab":{}},"source":["ls"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pi6_InWSR1pe","colab_type":"code","colab":{}},"source":["cd My Drive\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"c-MVhFmCR3s3","colab_type":"code","colab":{}},"source":["ls"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TZHCZvVRR4ZK","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"X-hEbwAffc0I","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}