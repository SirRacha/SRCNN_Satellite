{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SRCNN1_models.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"F9HXg40ZTJZ-","colab_type":"text"},"source":["## This notebook is a translation of the models.py file into the Colab specific .ipynb format.  \n","\n","Im struggling with how to call other files saved in the same Drive folder. Usually you would do an \"import soandso\" class that you've made elsewhere, but here im not sure.  \n"]},{"cell_type":"code","metadata":{"id":"Iil49KAsodVD","colab_type":"code","outputId":"93cc4890-beae-47dd-cc5d-e48046ebdc9f","executionInfo":{"status":"ok","timestamp":1566583737167,"user_tz":300,"elapsed":13047,"user":{"displayName":"Chris H","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBQMaEnOTE9AQl348tL3rMuRnYS2dmRI2CD2FjZ8w=s64","userId":"06776436809075546973"}},"colab":{"base_uri":"https://localhost:8080/","height":293}},"source":["!pip install -U scipy==1.2.0"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting scipy==1.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/e6/6d4edaceee6a110ecf6f318482f5229792f143e468b34a631f5a0899f56d/scipy-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (26.6MB)\n","\u001b[K     |████████████████████████████████| 26.6MB 1.4MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.2.0) (1.16.4)\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: scipy\n","  Found existing installation: scipy 1.3.1\n","    Uninstalling scipy-1.3.1:\n","      Successfully uninstalled scipy-1.3.1\n","Successfully installed scipy-1.2.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["scipy"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"6kscu0OWHgco","colab_type":"code","outputId":"9dc80fbe-f557-4499-b1a2-83f0adcba663","executionInfo":{"status":"ok","timestamp":1566692011034,"user_tz":300,"elapsed":1696,"user":{"displayName":"Ken L","photoUrl":"","userId":"02403260887810472531"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["!ls sample_data"],"execution_count":0,"outputs":[{"output_type":"stream","text":["anscombe.json\t\t      mnist_test.csv\n","california_housing_test.csv   mnist_train_small.csv\n","california_housing_train.csv  README.md\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"s1lwe0MhRD2e","colab_type":"code","outputId":"3820229c-66ae-4a3a-ee50-fc73f10557d6","executionInfo":{"status":"ok","timestamp":1566583765052,"user_tz":300,"elapsed":2671,"user":{"displayName":"Chris H","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBQMaEnOTE9AQl348tL3rMuRnYS2dmRI2CD2FjZ8w=s64","userId":"06776436809075546973"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["## Run this code to confirm TensorFlow can see the GPU.  ##\n","\n","import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"E1Gs7DWKOuIy","colab_type":"code","outputId":"28b6266e-2f67-4827-ebd6-7a9249d7c87f","executionInfo":{"status":"ok","timestamp":1566583703396,"user_tz":300,"elapsed":28060,"user":{"displayName":"Chris H","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBQMaEnOTE9AQl348tL3rMuRnYS2dmRI2CD2FjZ8w=s64","userId":"06776436809075546973"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["## Connect to MyDrive ##\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","root_dir = \"/content/drive/My Drive/\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NhF3906YuFTo","colab_type":"code","outputId":"614df189-56cf-4451-86d1-642f403eadd7","executionInfo":{"status":"ok","timestamp":1566583771494,"user_tz":300,"elapsed":3516,"user":{"displayName":"Chris H","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBQMaEnOTE9AQl348tL3rMuRnYS2dmRI2CD2FjZ8w=s64","userId":"06776436809075546973"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["!ls"],"execution_count":0,"outputs":[{"output_type":"stream","text":["drive  sample_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"U5T7IyNeuRpX","colab_type":"code","colab":{}},"source":["## os library is used to assign filepath locations too\n","import os\n","os.chdir('./drive/My Drive/Colab Notebooks/Image-Super-Resolution')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uHy9_FzzPaet","colab_type":"code","outputId":"48f99261-4fe9-4a27-947e-94e28d99a5c6","executionInfo":{"status":"ok","timestamp":1566583778206,"user_tz":300,"elapsed":3414,"user":{"displayName":"Chris H","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBQMaEnOTE9AQl348tL3rMuRnYS2dmRI2CD2FjZ8w=s64","userId":"06776436809075546973"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["!ls"],"execution_count":0,"outputs":[{"output_type":"stream","text":[" advanced.py\t       input_images.zip\t\t SRCNN1_main.ipynb\n"," architectures\t       main.py\t\t\t SRCNN1_models.ipynb\n","'Copy of main.ipynb'   models.py\t\t SRCNN1_Notes.ipynb\n"," Dataset\t       output_images\t\t tests.py\n"," distill_network.py    __pycache__\t\t val_images\n"," Framework-Update.md   README.md\t\t weights\n"," img_utils.py\t       results\t\t\t windows_helper\n"," input_images\t       SRCNN1_image_util.ipynb\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YTr1QMftoeVy","colab_type":"code","colab":{}},"source":["import sys\n","sys.path.append('/content/drive/My Drive/Colab Notebooks/Image-Super-Resolution')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xnjdCv1sN82N","colab_type":"code","outputId":"b0700c8b-0953-44b9-ebeb-4e300972ba2a","executionInfo":{"status":"ok","timestamp":1566583788355,"user_tz":300,"elapsed":3203,"user":{"displayName":"Chris H","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBQMaEnOTE9AQl348tL3rMuRnYS2dmRI2CD2FjZ8w=s64","userId":"06776436809075546973"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["####  Set up environment versioning  ####\n","\n","from __future__ import print_function, division\n","\n","from keras.models import Model\n","from keras.layers import Concatenate, Add, Average, Input, Dense, Flatten, BatchNormalization, Activation, LeakyReLU\n","from keras.layers.convolutional import Convolution2D, MaxPooling2D, UpSampling2D, Convolution2DTranspose\n","from keras import backend as K\n","from keras.utils.np_utils import to_categorical\n","import keras.callbacks as callbacks\n","import keras.optimizers as optimizers\n","\n","from advanced import HistoryCheckpoint, SubPixelUpscaling, non_local_block, TensorBoardBatch\n","import img_utils\n","\n","import numpy as np\n","import os\n","import time\n","import warnings\n","\n","try:\n","    import cv2\n","    _cv2_available = True\n","except:\n","    warnings.warn('Could not load opencv properly. This may affect the quality of output images.')\n","    _cv2_available = False\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"6NOsKBL7QVRH","colab_type":"code","colab":{}},"source":["## Only to be done in Colab ## bc I cant figure out how to get Colab to run other files in \n","## the same folder like a normal program works on my local  ##\n","\n","base_dataset_dir = r\"/content/drive/My Drive/Colab Notebooks/Image-Super-Resolution\" + r\"/Dataset/\"\n","\n","output_path = base_dataset_dir + \"train_images/train/\"\n","validation_output_path = base_dataset_dir + r\"train_images/validation/\"\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JS8omJqDOP94","colab_type":"code","colab":{}},"source":["train_path = img_utils.output_path\n","validation_path = img_utils.validation_output_path\n","path_X = img_utils.output_path + \"X/\"\n","path_Y = img_utils.output_path + \"y/\"\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cD_Dj-NmOQKo","colab_type":"code","colab":{}},"source":["\n","def PSNRLoss(y_true, y_pred):\n","    \"\"\"\n","    PSNR is Peek Signal to Noise Ratio, which is similar to mean squared error.\n","\n","    It can be calculated as\n","    PSNR = 20 * log10(MAXp) - 10 * log10(MSE)\n","\n","    When providing an unscaled input, MAXp = 255. Therefore 20 * log10(255)== 48.1308036087.\n","    However, since we are scaling our input, MAXp = 1. Therefore 20 * log10(1) = 0.\n","    Thus we remove that component completely and only compute the remaining MSE component.\n","    \"\"\"\n","    return -10. * K.log(K.mean(K.square(y_pred - y_true))) / K.log(10.)\n","\n","def psnr(y_true, y_pred):\n","    assert y_true.shape == y_pred.shape, \"Cannot calculate PSNR. Input shapes not same.\" \\\n","                                         \" y_true shape = %s, y_pred shape = %s\" % (str(y_true.shape),\n","                                                                                   str(y_pred.shape))\n","\n","    return -10. * np.log10(np.mean(np.square(y_pred - y_true)))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EOGF-dnjpIN8","colab_type":"code","colab":{}},"source":["\n","class BaseSuperResolutionModel(object):\n","\n","    def __init__(self, model_name, scale_factor):\n","        \"\"\"\n","        Base model to provide a standard interface of adding Super Resolution models\n","        \"\"\"\n","        self.model = None # type: Model\n","        self.model_name = model_name\n","        self.scale_factor = scale_factor\n","        self.weight_path = None\n","\n","        self.type_scale_type = \"norm\" # Default = \"norm\" = 1. / 255\n","        self.type_requires_divisible_shape = False\n","        self.type_true_upscaling = False\n","\n","        self.evaluation_func = None\n","        self.uses_learning_phase = False\n","\n","    def create_model(self, height=32, width=32, channels=3, load_weights=False, batch_size=128) -> Model:\n","        \"\"\"\n","        Subclass dependent implementation.\n","        \"\"\"\n","        if self.type_requires_divisible_shape and height is not None and width is not None:\n","            assert height * img_utils._image_scale_multiplier % 4 == 0, \"Height of the image must be divisible by 4\"\n","            assert width * img_utils._image_scale_multiplier % 4 == 0, \"Width of the image must be divisible by 4\"\n","\n","        if K.image_dim_ordering() == \"th\":\n","            if width is not None and height is not None:\n","                shape = (channels, width * img_utils._image_scale_multiplier, height * img_utils._image_scale_multiplier)\n","            else:\n","                shape = (channels, None, None)\n","        else:\n","            if width is not None and height is not None:\n","                shape = (width * img_utils._image_scale_multiplier, height * img_utils._image_scale_multiplier, channels)\n","            else:\n","                shape = (None, None, channels)\n","\n","        init = Input(shape=shape)\n","\n","        return init\n","\n","    def fit(self, batch_size=128, nb_epochs=100, save_history=True, history_fn=\"Model History.txt\") -> Model:\n","        \"\"\"\n","        Standard method to train any of the models.\n","        \"\"\"\n","\n","        samples_per_epoch = img_utils.image_count()\n","        val_count = img_utils.val_image_count()\n","        if self.model == None: self.create_model(batch_size=batch_size)\n","\n","        callback_list = [callbacks.ModelCheckpoint(self.weight_path, monitor='val_PSNRLoss', save_best_only=True,\n","                                                   mode='max', save_weights_only=True, verbose=2)]\n","        if save_history:\n","            callback_list.append(HistoryCheckpoint(history_fn))\n","\n","            if K.backend() == 'tensorflow':\n","                log_dir = './%s_logs/' % self.model_name\n","                tensorboard = TensorBoardBatch(log_dir, batch_size=batch_size)\n","                callback_list.append(tensorboard)\n","\n","        print(\"Training model : %s\" % (self.__class__.__name__))\n","        self.model.fit_generator(img_utils.image_generator(train_path, scale_factor=self.scale_factor,\n","                                                           small_train_images=self.type_true_upscaling,\n","                                                           batch_size=batch_size),\n","                                 steps_per_epoch=samples_per_epoch // batch_size + 1,\n","                                 epochs=nb_epochs, callbacks=callback_list,\n","                                 validation_data=img_utils.image_generator(validation_path,\n","                                                                           scale_factor=self.scale_factor,\n","                                                                           small_train_images=self.type_true_upscaling,\n","                                                                           batch_size=batch_size),\n","                                 validation_steps=val_count // batch_size + 1)\n","\n","        return self.model\n","\n","    def evaluate(self, validation_dir):\n","        if self.type_requires_divisible_shape and not self.type_true_upscaling:\n","            _evaluate_denoise(self, validation_dir)\n","        else:\n","            _evaluate(self, validation_dir)\n","\n","\n","    def upscale(self, img_path, save_intermediate=False, return_image=False, suffix=\"scaled\",\n","                patch_size=8, mode=\"patch\", verbose=True):\n","        \"\"\"\n","        Standard method to upscale an image.\n","\n","        :param img_path:  path to the image\n","        :param save_intermediate: saves the intermediate upscaled image (bilinear upscale)\n","        :param return_image: returns a image of shape (height, width, channels).\n","        :param suffix: suffix of upscaled image\n","        :param patch_size: size of each patch grid\n","        :param verbose: whether to print messages\n","        :param mode: mode of upscaling. Can be \"patch\" or \"fast\"\n","        \"\"\"\n","        import os\n","        from scipy.misc import imread, imresize, imsave\n","\n","        # Destination path\n","        path = os.path.splitext(img_path)\n","        filename = path[0] + \"_\" + suffix + \"(%dx)\" % (self.scale_factor) + path[1]\n","\n","        # Read image\n","        scale_factor = int(self.scale_factor)\n","        true_img = imread(img_path, mode='RGB')\n","        init_dim_1, init_dim_2 = true_img.shape[0], true_img.shape[1]\n","        if verbose: print(\"Old Size : \", true_img.shape)\n","        if verbose: print(\"New Size : (%d, %d, 3)\" % (init_dim_1 * scale_factor, init_dim_2 * scale_factor))\n","\n","        img_dim_1, img_dim_2 = 0, 0\n","\n","        if mode == \"patch\" and self.type_true_upscaling:\n","            # Overriding mode for True Upscaling models\n","            mode = 'fast'\n","            print(\"Patch mode does not work with True Upscaling models yet. Defaulting to mode='fast'\")\n","\n","        if mode == 'patch':\n","            # Create patches\n","            if self.type_requires_divisible_shape:\n","                if patch_size % 4 != 0:\n","                    print(\"Deep Denoise requires patch size which is multiple of 4.\\nSetting patch_size = 8.\")\n","                    patch_size = 8\n","\n","            images = img_utils.make_patches(true_img, scale_factor, patch_size, verbose)\n","\n","            nb_images = images.shape[0]\n","            img_dim_1, img_dim_2 = images.shape[1], images.shape[2]\n","            print(\"Number of patches = %d, Patch Shape = (%d, %d)\" % (nb_images, img_dim_2, img_dim_1))\n","        else:\n","            # Use full image for super resolution\n","            img_dim_1, img_dim_2 = self.__match_autoencoder_size(img_dim_1, img_dim_2, init_dim_1, init_dim_2,\n","                                                                 scale_factor)\n","\n","            images = imresize(true_img, (img_dim_1, img_dim_2))\n","            images = np.expand_dims(images, axis=0)\n","            print(\"Image is reshaped to : (%d, %d, %d)\" % (images.shape[1], images.shape[2], images.shape[3]))\n","\n","        # Save intermediate bilinear scaled image is needed for comparison.\n","        intermediate_img = None\n","        if save_intermediate:\n","            if verbose: print(\"Saving intermediate image.\")\n","            fn = path[0] + \"_intermediate_\" + path[1]\n","            intermediate_img = imresize(true_img, (init_dim_1 * scale_factor, init_dim_2 * scale_factor))\n","            imsave(fn, intermediate_img)\n","\n","        # Transpose and Process images\n","        if K.image_dim_ordering() == \"th\":\n","            img_conv = images.transpose((0, 3, 1, 2)).astype(np.float32) / 255.\n","        else:\n","            img_conv = images.astype(np.float32) / 255.\n","\n","        model = self.create_model(img_dim_2, img_dim_1, load_weights=True)\n","        if verbose: print(\"Model loaded.\")\n","\n","        # Create prediction for image patches\n","        result = model.predict(img_conv, batch_size=128, verbose=verbose)\n","\n","        if verbose: print(\"De-processing images.\")\n","\n","         # Deprocess patches\n","        if K.image_dim_ordering() == \"th\":\n","            result = result.transpose((0, 2, 3, 1)).astype(np.float32) * 255.\n","        else:\n","            result = result.astype(np.float32) * 255.\n","\n","        # Output shape is (original_width * scale, original_height * scale, nb_channels)\n","        if mode == 'patch':\n","            out_shape = (init_dim_1 * scale_factor, init_dim_2 * scale_factor, 3)\n","            result = img_utils.combine_patches(result, out_shape, scale_factor)\n","        else:\n","            result = result[0, :, :, :] # Access the 3 Dimensional image vector\n","\n","        result = np.clip(result, 0, 255).astype('uint8')\n","\n","        if _cv2_available:\n","            # used to remove noisy edges\n","            result = cv2.pyrUp(result)\n","            result = cv2.medianBlur(result, 3)\n","            result = cv2.pyrDown(result)\n","\n","        if verbose: print(\"\\nCompleted De-processing image.\")\n","\n","        if return_image:\n","            # Return the image without saving. Useful for testing images.\n","            return result\n","\n","        if verbose: print(\"Saving image.\")\n","        imsave(filename, result)\n","\n","    def __match_autoencoder_size(self, img_dim_1, img_dim_2, init_dim_1, init_dim_2, scale_factor):\n","        if self.type_requires_divisible_shape:\n","            if not self.type_true_upscaling:\n","                # AE model but not true upsampling\n","                if ((init_dim_2 * scale_factor) % 4 != 0) or ((init_dim_1 * scale_factor) % 4 != 0) or \\\n","                        (init_dim_2 % 2 != 0) or (init_dim_1 % 2 != 0):\n","\n","                    print(\"AE models requires image size which is multiple of 4.\")\n","                    img_dim_2 = ((init_dim_2 * scale_factor) // 4) * 4\n","                    img_dim_1 = ((init_dim_1 * scale_factor) // 4) * 4\n","\n","                else:\n","                    # No change required\n","                    img_dim_2, img_dim_1 = init_dim_2 * scale_factor, init_dim_1 * scale_factor\n","            else:\n","                # AE model and true upsampling\n","                if ((init_dim_2) % 4 != 0) or ((init_dim_1) % 4 != 0) or \\\n","                        (init_dim_2 % 2 != 0) or (init_dim_1 % 2 != 0):\n","\n","                    print(\"AE models requires image size which is multiple of 4.\")\n","                    img_dim_2 = ((init_dim_2) // 4) * 4\n","                    img_dim_1 = ((init_dim_1) // 4) * 4\n","\n","                else:\n","                    # No change required\n","                    img_dim_2, img_dim_1 = init_dim_2, init_dim_1\n","        else:\n","            # Not AE but true upsampling\n","            if self.type_true_upscaling:\n","                img_dim_2, img_dim_1 = init_dim_2, init_dim_1\n","            else:\n","                # Not AE and not true upsampling\n","                img_dim_2, img_dim_1 = init_dim_2 * scale_factor, init_dim_1 * scale_factor\n","\n","        return img_dim_1, img_dim_2,\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wYibJ-YLpOEJ","colab_type":"code","colab":{}},"source":["\n","def _evaluate(sr_model : BaseSuperResolutionModel, validation_dir, scale_pred=False):\n","    \"\"\"\n","    Evaluates the model on the Validation images\n","    \"\"\"\n","    print(\"Validating %s model\" % sr_model.model_name)\n","    if sr_model.model == None: sr_model.create_model(load_weights=True)\n","    if sr_model.evaluation_func is None:\n","        if sr_model.uses_learning_phase:\n","            sr_model.evaluation_func = K.function([sr_model.model.layers[0].input, K.learning_phase()],\n","                                                  [sr_model.model.layers[-1].output])\n","        else:\n","            sr_model.evaluation_func = K.function([sr_model.model.layers[0].input],\n","                                              [sr_model.model.layers[-1].output])\n","    predict_path = \"val_predict/\"\n","    if not os.path.exists(predict_path):\n","        os.makedirs(predict_path)\n","    validation_path_set5 = validation_dir + \"set5/\"\n","    validation_path_set14 = validation_dir + \"set14/\"\n","    validation_dirs = [validation_path_set5, validation_path_set14]\n","    for val_dir in validation_dirs:\n","        image_fns = [name for name in os.listdir(val_dir)]\n","        nb_images = len(image_fns)\n","        print(\"Validating %d images from path %s\" % (nb_images, val_dir))\n","\n","        total_psnr = 0.0\n","\n","        for impath in os.listdir(val_dir):\n","            t1 = time.time()\n","\n","            # Input image\n","            y = img_utils.imread(val_dir + impath, mode='RGB')\n","            width, height, _ = y.shape\n","\n","            if sr_model.type_requires_divisible_shape:\n","                # Denoise models require precise width and height, divisible by 4\n","\n","                if ((width // sr_model.scale_factor) % 4 != 0) or ((height // sr_model.scale_factor) % 4 != 0) \\\n","                        or (width % 2 != 0) or (height % 2 != 0):\n","                    width = ((width // sr_model.scale_factor) // 4) * 4 * sr_model.scale_factor\n","                    height = ((height // sr_model.scale_factor) // 4) * 4 * sr_model.scale_factor\n","\n","                    print(\"Model %s require the image size to be divisible by 4. New image size = (%d, %d)\" % \\\n","                          (sr_model.model_name, width, height))\n","\n","                    y = img_utils.imresize(y, (width, height), interp='bicubic')\n","\n","            y = y.astype('float32')\n","            x_width = width if not sr_model.type_true_upscaling else width // sr_model.scale_factor\n","            x_height = height if not sr_model.type_true_upscaling else height // sr_model.scale_factor\n","\n","            x_temp = y.copy()\n","\n","            if sr_model.type_scale_type == \"tanh\":\n","                x_temp = (x_temp - 127.5) / 127.5\n","                y = (y - 127.5) / 127.5\n","            else:\n","                x_temp /= 255.\n","                y /= 255.\n","\n","            y = np.expand_dims(y, axis=0)\n","\n","            img = img_utils.imresize(x_temp, (x_width, x_height),\n","                                     interp='bicubic')\n","\n","            if not sr_model.type_true_upscaling:\n","                img = img_utils.imresize(img, (x_width, x_height), interp='bicubic')\n","\n","\n","            x = np.expand_dims(img, axis=0)\n","\n","            if K.image_dim_ordering() == \"th\":\n","                x = x.transpose((0, 3, 1, 2))\n","                y = y.transpose((0, 3, 1, 2))\n","\n","            if sr_model.uses_learning_phase:\n","                y_pred = sr_model.evaluation_func([x, 0])[0][0]\n","            else:\n","                y_pred = sr_model.evaluation_func([x])[0][0]\n","\n","            if scale_pred:\n","                if sr_model.type_scale_type == \"tanh\":\n","                    y_pred = (y_pred + 1) * 127.5\n","                else:\n","                    y_pred *= 255.\n","\n","            if sr_model.type_scale_type == 'tanh':\n","                y = (y + 1) / 2\n","\n","            psnr_val = psnr(y[0], np.clip(y_pred, 0, 255) / 255)\n","            total_psnr += psnr_val\n","\n","            t2 = time.time()\n","            print(\"Validated image : %s, Time required : %0.2f, PSNR value : %0.4f\" % (impath, t2 - t1, psnr_val))\n","\n","            generated_path = predict_path + \"%s_%s_generated.png\" % (sr_model.model_name, os.path.splitext(impath)[0])\n","\n","            if K.image_dim_ordering() == \"th\":\n","                y_pred = y_pred.transpose((1, 2, 0))\n","\n","            y_pred = np.clip(y_pred, 0, 255).astype('uint8')\n","            img_utils.imsave(generated_path, y_pred)\n","\n","        print(\"Average PRNS value of validation images = %00.4f \\n\" % (total_psnr / nb_images))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"J4JUSBNLpTzB","colab_type":"code","colab":{}},"source":["\n","def _evaluate_denoise(sr_model : BaseSuperResolutionModel, validation_dir, scale_pred=False):\n","    print(\"Validating %s model\" % sr_model.model_name)\n","    predict_path = \"val_predict/\"\n","    if not os.path.exists(predict_path):\n","        os.makedirs(predict_path)\n","\n","    validation_path_set5 = validation_dir + \"set5/\"\n","    validation_path_set14 = validation_dir + \"set14/\"\n","\n","    validation_dirs = [validation_path_set5, validation_path_set14]\n","    for val_dir in validation_dirs:\n","        image_fns = [name for name in os.listdir(val_dir)]\n","        nb_images = len(image_fns)\n","        print(\"Validating %d images from path %s\" % (nb_images, val_dir))\n","\n","        total_psnr = 0.0\n","\n","        for impath in os.listdir(val_dir):\n","            t1 = time.time()\n","\n","            # Input image\n","            y = img_utils.imread(val_dir + impath, mode='RGB')\n","            width, height, _ = y.shape\n","\n","            if ((width // sr_model.scale_factor) % 4 != 0) or ((height // sr_model.scale_factor) % 4 != 0) \\\n","                    or (width % 2 != 0) or (height % 2 != 0):\n","                width = ((width // sr_model.scale_factor) // 4) * 4 * sr_model.scale_factor\n","                height = ((height // sr_model.scale_factor) // 4) * 4 * sr_model.scale_factor\n","\n","                print(\"Model %s require the image size to be divisible by 4. New image size = (%d, %d)\" % \\\n","                      (sr_model.model_name, width, height))\n","\n","                y = img_utils.imresize(y, (width, height), interp='bicubic')\n","\n","            y = y.astype('float32')\n","            y = np.expand_dims(y, axis=0)\n","\n","            x_temp = y.copy()\n","\n","            if sr_model.type_scale_type == \"tanh\":\n","                x_temp = (x_temp - 127.5) / 127.5\n","                y = (y - 127.5) / 127.5\n","            else:\n","                x_temp /= 255.\n","                y /= 255.\n","\n","            img = img_utils.imresize(x_temp[0], (width // sr_model.scale_factor, height // sr_model.scale_factor),\n","                                     interp='bicubic', mode='RGB')\n","\n","            if not sr_model.type_true_upscaling:\n","                img = img_utils.imresize(img, (width, height), interp='bicubic')\n","\n","            x = np.expand_dims(img, axis=0)\n","\n","            if K.image_dim_ordering() == \"th\":\n","                x = x.transpose((0, 3, 1, 2))\n","                y = y.transpose((0, 3, 1, 2))\n","\n","            sr_model.model = sr_model.create_model(height, width, load_weights=True)\n","\n","            if sr_model.evaluation_func is None:\n","                if sr_model.uses_learning_phase:\n","                    sr_model.evaluation_func = K.function([sr_model.model.layers[0].input, K.learning_phase()],\n","                                                          [sr_model.model.layers[-1].output])\n","                else:\n","                    sr_model.evaluation_func = K.function([sr_model.model.layers[0].input],\n","                                                          [sr_model.model.layers[-1].output])\n","\n","            if sr_model.uses_learning_phase:\n","                y_pred = sr_model.evaluation_func([x, 0])[0][0]\n","            else:\n","                y_pred = sr_model.evaluation_func([x])[0][0]\n","\n","            if scale_pred:\n","                if sr_model.type_scale_type == \"tanh\":\n","                    y_pred = (y_pred + 1) * 127.5\n","                else:\n","                    y_pred *= 255.\n","\n","            if sr_model.type_scale_type == 'tanh':\n","                y = (y + 1) / 2\n","\n","            psnr_val = psnr(y[0], np.clip(y_pred, 0, 255) / 255)\n","            total_psnr += psnr_val\n","\n","            t2 = time.time()\n","            print(\"Validated image : %s, Time required : %0.2f, PSNR value : %0.4f\" % (impath, t2 - t1, psnr_val))\n","\n","            generated_path = predict_path + \"%s_%s_generated.png\" % (sr_model.model_name, os.path.splitext(impath)[0])\n","\n","            if K.image_dim_ordering() == \"th\":\n","                y_pred = y_pred.transpose((1, 2, 0))\n","\n","            y_pred = np.clip(y_pred, 0, 255).astype('uint8')\n","            img_utils.imsave(generated_path, y_pred)\n","\n","        print(\"Average PRNS value of validation images = %00.4f \\n\" % (total_psnr / nb_images))\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ryeKGi3epX6o","colab_type":"code","colab":{}},"source":["\n","class ImageSuperResolutionModel(BaseSuperResolutionModel):\n","\n","    def __init__(self, scale_factor):\n","        super(ImageSuperResolutionModel, self).__init__(\"Image SR\", scale_factor)\n","\n","        self.f1 = 9\n","        self.f2 = 1\n","        self.f3 = 5\n","\n","        self.n1 = 64\n","        self.n2 = 32\n","\n","        self.weight_path = \"weights/SR Weights %dX.h5\" % (self.scale_factor)\n","\n","    def create_model(self, height=32, width=32, channels=3, load_weights=False, batch_size=128):\n","        \"\"\"\n","            Creates a model to be used to scale images of specific height and width.\n","        \"\"\"\n","        init = super(ImageSuperResolutionModel, self).create_model(height, width, channels, load_weights, batch_size)\n","\n","        x = Convolution2D(self.n1, (self.f1, self.f1), activation='relu', padding='same', name='level1')(init)\n","        x = Convolution2D(self.n2, (self.f2, self.f2), activation='relu', padding='same', name='level2')(x)\n","\n","        out = Convolution2D(channels, (self.f3, self.f3), padding='same', name='output')(x)\n","\n","        model = Model(init, out)\n","\n","        adam = optimizers.Adam(lr=1e-3)\n","        model.compile(optimizer=adam, loss='mse', metrics=[PSNRLoss])\n","        if load_weights: model.load_weights(self.weight_path)\n","\n","        self.model = model\n","        return model\n","\n","    def fit(self, batch_size=128, nb_epochs=100, save_history=True, history_fn=\"SRCNN History.txt\"):\n","        return super(ImageSuperResolutionModel, self).fit(batch_size, nb_epochs, save_history, history_fn)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qgndKVNMpb01","colab_type":"code","colab":{}},"source":["\n","class ExpantionSuperResolution(BaseSuperResolutionModel):\n","\n","    def __init__(self, scale_factor):\n","        super(ExpantionSuperResolution, self).__init__(\"Expanded Image SR\", scale_factor)\n","\n","        self.f1 = 9\n","        self.f2_1 = 1\n","        self.f2_2 = 3\n","        self.f2_3 = 5\n","        self.f3 = 5\n","\n","        self.n1 = 64\n","        self.n2 = 32\n","\n","        self.weight_path = \"weights/Expantion SR Weights %dX.h5\" % (self.scale_factor)\n","\n","    def create_model(self, height=32, width=32, channels=3, load_weights=False, batch_size=128):\n","        \"\"\"\n","            Creates a model to be used to scale images of specific height and width.\n","        \"\"\"\n","        init = super(ExpantionSuperResolution, self).create_model(height, width, channels, load_weights, batch_size)\n","\n","        x = Convolution2D(self.n1, (self.f1, self.f1), activation='relu', padding='same', name='level1')(init)\n","\n","        x1 = Convolution2D(self.n2, (self.f2_1, self.f2_1), activation='relu', padding='same', name='lavel1_1')(x)\n","        x2 = Convolution2D(self.n2, (self.f2_2, self.f2_2), activation='relu', padding='same', name='lavel1_2')(x)\n","        x3 = Convolution2D(self.n2, (self.f2_3, self.f2_3), activation='relu', padding='same', name='lavel1_3')(x)\n","\n","        x = Average()([x1, x2, x3])\n","\n","        out = Convolution2D(channels, (self.f3, self.f3), activation='relu', padding='same', name='output')(x)\n","\n","        model = Model(init, out)\n","        adam = optimizers.Adam(lr=1e-3)\n","        model.compile(optimizer=adam, loss='mse', metrics=[PSNRLoss])\n","        if load_weights: model.load_weights(self.weight_path)\n","\n","        self.model = model\n","        return model\n","\n","    def fit(self, batch_size=128, nb_epochs=100, save_history=True, history_fn=\"ESRCNN History.txt\"):\n","        return super(ExpantionSuperResolution, self).fit(batch_size, nb_epochs, save_history, history_fn)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SE7ewNq8pfPT","colab_type":"code","colab":{}},"source":["\n","class DenoisingAutoEncoderSR(BaseSuperResolutionModel):\n","\n","    def __init__(self, scale_factor):\n","        super(DenoisingAutoEncoderSR, self).__init__(\"Denoise AutoEncoder SR\", scale_factor)\n","\n","        self.n1 = 64\n","        self.n2 = 32\n","\n","        self.weight_path = \"weights/Denoising AutoEncoder %dX.h5\" % (self.scale_factor)\n","\n","    def create_model(self, height=32, width=32, channels=3, load_weights=False, batch_size=128):\n","        \"\"\"\n","            Creates a model to remove / reduce noise from upscaled images.\n","        \"\"\"\n","        from keras.layers.convolutional import Deconvolution2D\n","\n","        # Perform check that model input shape is divisible by 4\n","        init = super(DenoisingAutoEncoderSR, self).create_model(height, width, channels, load_weights, batch_size)\n","\n","        if K.image_dim_ordering() == \"th\":\n","            output_shape = (None, channels, width, height)\n","        else:\n","            output_shape = (None, width, height, channels)\n","\n","        level1_1 = Convolution2D(self.n1, (3, 3), activation='relu', padding='same')(init)\n","        level2_1 = Convolution2D(self.n1, (3, 3), activation='relu', padding='same')(level1_1)\n","\n","        level2_2 = Convolution2DTranspose(self.n1, (3, 3), activation='relu', padding='same')(level2_1)\n","        level2 = Add()([level2_1, level2_2])\n","\n","        level1_2 = Convolution2DTranspose(self.n1, (3, 3), activation='relu', padding='same')(level2)\n","        level1 = Add()([level1_1, level1_2])\n","\n","        decoded = Convolution2D(channels, (5, 5), activation='linear', padding='same')(level1)\n","\n","        model = Model(init, decoded)\n","        adam = optimizers.Adam(lr=1e-3)\n","        model.compile(optimizer=adam, loss='mse', metrics=[PSNRLoss])\n","        if load_weights: model.load_weights(self.weight_path)\n","\n","        self.model = model\n","        return model\n","\n","    def fit(self, batch_size=128, nb_epochs=100, save_history=True, history_fn=\"DSRCNN History.txt\"):\n","        return super(DenoisingAutoEncoderSR, self).fit(batch_size, nb_epochs, save_history, history_fn)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GmDjvs5iph40","colab_type":"code","colab":{}},"source":["\n","class DeepDenoiseSR(BaseSuperResolutionModel):\n","\n","    def __init__(self, scale_factor):\n","        super(DeepDenoiseSR, self).__init__(\"Deep Denoise SR\", scale_factor)\n","\n","        # Treat this model as a denoising auto encoder\n","        # Force the fit, evaluate and upscale methods to take special care about image shape\n","        self.type_requires_divisible_shape = True\n","\n","        self.n1 = 64\n","        self.n2 = 128\n","        self.n3 = 256\n","\n","        self.weight_path = \"weights/Deep Denoise Weights %dX.h5\" % (self.scale_factor)\n","\n","    def create_model(self, height=32, width=32, channels=3, load_weights=False, batch_size=128):\n","        # Perform check that model input shape is divisible by 4\n","        init = super(DeepDenoiseSR, self).create_model(height, width, channels, load_weights, batch_size)\n","\n","        c1 = Convolution2D(self.n1, (3, 3), activation='relu', padding='same')(init)\n","        c1 = Convolution2D(self.n1, (3, 3), activation='relu', padding='same')(c1)\n","\n","        x = MaxPooling2D((2, 2))(c1)\n","\n","        c2 = Convolution2D(self.n2, (3, 3), activation='relu', padding='same')(x)\n","        c2 = Convolution2D(self.n2, (3, 3), activation='relu', padding='same')(c2)\n","\n","        x = MaxPooling2D((2, 2))(c2)\n","\n","        c3 = Convolution2D(self.n3, (3, 3), activation='relu', padding='same')(x)\n","\n","        x = UpSampling2D()(c3)\n","\n","        c2_2 = Convolution2D(self.n2, (3, 3), activation='relu', padding='same')(x)\n","        c2_2 = Convolution2D(self.n2, (3, 3), activation='relu', padding='same')(c2_2)\n","\n","        m1 = Add()([c2, c2_2])\n","        m1 = UpSampling2D()(m1)\n","\n","        c1_2 = Convolution2D(self.n1, (3, 3), activation='relu', padding='same')(m1)\n","        c1_2 = Convolution2D(self.n1, (3, 3), activation='relu', padding='same')(c1_2)\n","\n","        m2 = Add()([c1, c1_2])\n","\n","        decoded = Convolution2D(channels, 5, 5, activation='linear', border_mode='same')(m2)\n","\n","        model = Model(init, decoded)\n","        adam = optimizers.Adam(lr=1e-3)\n","        model.compile(optimizer=adam, loss='mse', metrics=[PSNRLoss])\n","        if load_weights: model.load_weights(self.weight_path)\n","\n","        self.model = model\n","        return model\n","\n","    def fit(self, batch_size=128, nb_epochs=100, save_history=True, history_fn=\"Deep DSRCNN History.txt\"):\n","        super(DeepDenoiseSR, self).fit(batch_size, nb_epochs, save_history, history_fn)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"P_G2GNwfplsq","colab_type":"code","colab":{}},"source":["\n","class ResNetSR(BaseSuperResolutionModel):\n","\n","    def __init__(self, scale_factor):\n","        super(ResNetSR, self).__init__(\"ResNetSR\", scale_factor)\n","\n","        # Treat this model as a denoising auto encoder\n","        # Force the fit, evaluate and upscale methods to take special care about image shape\n","        self.type_requires_divisible_shape = True\n","        self.uses_learning_phase = False\n","\n","        self.n = 64\n","        self.mode = 2\n","\n","        self.weight_path = \"weights/ResNetSR %dX.h5\" % (self.scale_factor)\n","        self.type_true_upscaling = True\n","\n","    def create_model(self, height=32, width=32, channels=3, load_weights=False, batch_size=128):\n","        init =  super(ResNetSR, self).create_model(height, width, channels, load_weights, batch_size)\n","\n","        x0 = Convolution2D(64, (3, 3), activation='relu', padding='same', name='sr_res_conv1')(init)\n","\n","        #x1 = Convolution2D(64, (3, 3), activation='relu', padding='same', strides=(2, 2), name='sr_res_conv2')(x0)\n","\n","        #x2 = Convolution2D(64, (3, 3), activation='relu', padding='same', strides=(2, 2), name='sr_res_conv3')(x1)\n","\n","        x = self._residual_block(x0, 1)\n","\n","        nb_residual = 5\n","        for i in range(nb_residual):\n","            x = self._residual_block(x, i + 2)\n","\n","        x = Add()([x, x0])\n","\n","        x = self._upscale_block(x, 1)\n","        #x = Add()([x, x1])\n","\n","        #x = self._upscale_block(x, 2)\n","        #x = Add()([x, x0])\n","\n","        x = Convolution2D(3, (3, 3), activation=\"linear\", padding='same', name='sr_res_conv_final')(x)\n","\n","        model = Model(init, x)\n","\n","        adam = optimizers.Adam(lr=1e-3)\n","        model.compile(optimizer=adam, loss='mse', metrics=[PSNRLoss])\n","        if load_weights: model.load_weights(self.weight_path, by_name=True)\n","\n","        self.model = model\n","        return model\n","\n","    def _residual_block(self, ip, id):\n","        mode = False if self.mode == 2 else None\n","        channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n","        init = ip\n","\n","        x = Convolution2D(64, (3, 3), activation='linear', padding='same',\n","                          name='sr_res_conv_' + str(id) + '_1')(ip)\n","        x = BatchNormalization(axis=channel_axis, name=\"sr_res_batchnorm_\" + str(id) + \"_1\")(x, training=mode)\n","        x = Activation('relu', name=\"sr_res_activation_\" + str(id) + \"_1\")(x)\n","\n","        x = Convolution2D(64, (3, 3), activation='linear', padding='same',\n","                          name='sr_res_conv_' + str(id) + '_2')(x)\n","        x = BatchNormalization(axis=channel_axis, name=\"sr_res_batchnorm_\" + str(id) + \"_2\")(x, training=mode)\n","\n","        m = Add(name=\"sr_res_merge_\" + str(id))([x, init])\n","\n","        return m\n","\n","    def _upscale_block(self, ip, id):\n","        init = ip\n","\n","        channel_dim = 1 if K.image_data_format() == 'channels_first' else -1\n","        channels = init._keras_shape[channel_dim]\n","\n","        #x = Convolution2D(256, (3, 3), activation=\"relu\", padding='same', name='sr_res_upconv1_%d' % id)(init)\n","        #x = SubPixelUpscaling(r=2, channels=self.n, name='sr_res_upscale1_%d' % id)(x)\n","        x = UpSampling2D()(init)\n","        x = Convolution2D(self.n, (3, 3), activation=\"relu\", padding='same', name='sr_res_filter1_%d' % id)(x)\n","\n","        # x = Convolution2DTranspose(channels, (4, 4), strides=(2, 2), padding='same', activation='relu',\n","        #                            name='upsampling_deconv_%d' % id)(init)\n","\n","        return x\n","\n","    def fit(self, batch_size=128, nb_epochs=100, save_history=True, history_fn=\"ResNetSR History.txt\"):\n","        super(ResNetSR, self).fit(batch_size, nb_epochs, save_history, history_fn)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JWetHIZPppLO","colab_type":"code","colab":{}},"source":["\n","class EfficientSubPixelConvolutionalSR(BaseSuperResolutionModel):\n","\n","    def __init__(self, scale_factor):\n","        super(EfficientSubPixelConvolutionalSR, self).__init__(\"ESPCNN SR\", scale_factor)\n","\n","        self.n1 = 64\n","        self.n2 = 32\n","\n","        self.f1 = 5\n","        self.f2 = 3\n","        self.f3 = 3\n","\n","        self.weight_path = \"weights/ESPCNN Weights %d.h5\" % scale_factor\n","\n","        # Flag to denote that this is a \"true\" upsampling model.\n","        # Image size will be multiplied by scale factor to get output image size\n","        self.true_upsampling = True\n","\n","    def create_model(self, height=16, width=16, channels=3, load_weights=False, batch_size=128):\n","        # Note height, width = 16 instead of 32 like usual\n","        init = super(EfficientSubPixelConvolutionalSR, self).create_model(height, width, channels,\n","                                                                          load_weights, batch_size)\n","\n","        x = Convolution2D(self.n1, (self.f1, self.f1), activation='relu', padding='same', name='level1')(init)\n","        x = Convolution2D(self.n2, (self.f2, self.f2), activation='relu', padding='same', name='level2')(x)\n","\n","        x = self._upscale_block(x, 1)\n","\n","        out = Convolution2D(3, (9, 9), activation='linear', padding='same')(x)\n","\n","        model = Model(init, out)\n","\n","        adam = optimizers.Adam(lr=1e-3)\n","        model.compile(optimizer=adam, loss='mse', metrics=[PSNRLoss])\n","        if load_weights: model.load_weights(self.weight_path)\n","\n","        self.model = model\n","        return model\n","\n","    def _upscale_block(self, ip, id):\n","        init = ip\n","\n","        # x = Convolution2D(256, (3, 3), activation=\"relu\", padding='same', name='espcnn_upconv1_%d' % id)(init)\n","        # x = SubPixelUpscaling(r=2, channels=self.n1, name='espcnn_upconv1__upscale1_%d' % id)(x)\n","        # x = Convolution2D(256, (3, 3), activation=\"relu\", padding='same', name='espcnn_upconv1_filter1_%d' % id)(x)\n","\n","        x = Convolution2DTranspose(128, (3, 3), strides=(2, 2), padding='same', activation='relu')(init)\n","\n","        return x\n","\n","    def fit(self, batch_size=128, nb_epochs=100, save_history=True, history_fn=\"ESPCNN History.txt\"):\n","        super(EfficientSubPixelConvolutionalSR, self).fit(batch_size, nb_epochs, save_history, history_fn)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CswFNAWLpufK","colab_type":"code","colab":{}},"source":["\n","class GANImageSuperResolutionModel(BaseSuperResolutionModel):\n","\n","    def __init__(self, scale_factor):\n","        super(GANImageSuperResolutionModel, self).__init__(\"GAN Image SR\", scale_factor)\n","\n","        self.f1 = 9\n","        self.f2 = 1\n","        self.f3 = 5\n","\n","        self.n1 = 64\n","        self.n2 = 32\n","\n","        self.gen_model = None # type: Model\n","        self.disc_model = None # type: Model\n","\n","        self.type_scale_type = 'tanh'\n","\n","        self.weight_path = \"weights/GAN SR Weights %dX.h5\" % (self.scale_factor)\n","        self.gen_weight_path = \"weights/GAN SR Pretrain Weights %dX.h5\" % (self.scale_factor)\n","        self.disc_weight_path = \"weights/GAN SR Discriminator Weights %dX.h5\" % (self.scale_factor)\n","\n","\n","    def create_model(self, mode='test', height=32, width=32, channels=3, load_weights=False, batch_size=128):\n","        \"\"\"\n","            Creates a model to be used to scale images of specific height and width.\n","        \"\"\"\n","        assert mode in ['test', 'train'], \"'mode' must be either 'train' or 'test'\"\n","\n","        channel_axis = 1 if K.image_dim_ordering() == 'th' else -1\n","\n","        gen_init = super(GANImageSuperResolutionModel, self).create_model(height, width, channels, load_weights, batch_size)\n","\n","        x = Convolution2D(self.n1, (self.f1, self.f1), activation='relu', padding='same', name='gen_level1')(gen_init)\n","        x = LeakyReLU(alpha=0.25)(x)\n","        x = Convolution2D(self.n2, (self.f2, self.f2), activation='relu', padding='same', name='gen_level2')(x)\n","        x = LeakyReLU(alpha=0.25)(x)\n","\n","        out = Convolution2D(channels, (self.f3, self.f3), activation='tanh', padding='same', name='gen_output')(x)\n","\n","        gen_model = Model(gen_init, out)\n","\n","        adam = optimizers.Adam(lr=1e-4)\n","        gen_model.compile(optimizer=adam, loss='mse', metrics=[PSNRLoss])\n","        if load_weights and mode == 'test': gen_model.load_weights(self.weight_path, by_name=True)\n","\n","        self.model = gen_model\n","\n","        if mode == 'train':\n","            try:\n","                gen_model.load_weights(self.weight_path)\n","            except:\n","                print('Could not load weights of GAN SR model for training.')\n","\n","        if mode == 'train':\n","            disc_init = super(GANImageSuperResolutionModel, self).create_model(height, width, channels, load_weights, batch_size)\n","\n","            x = Convolution2D(64, (3, 3), padding='same', name='disc_level1_1')(disc_init)\n","            x = LeakyReLU(alpha=0.25, name='disc_lr_1_1')(x)\n","            x = Convolution2D(64, (3, 3), padding='same', name='disc_level1_2',\n","                          strides=(2, 2))(x)\n","            x = LeakyReLU(alpha=0.25, name='disc_lr_1_2')(x)\n","            x = BatchNormalization(axis=channel_axis, name='disc_bn_1')(x, training=False)\n","\n","            x = Convolution2D(128, (3, 3), padding='same', name='disc_level2_1')(x)\n","            x = LeakyReLU(alpha=0.25, name='disc_lr_2_1')(x)\n","            x = Convolution2D(128, (3, 3), padding='same', name='disc_level2_2',\n","                              strides=(2, 2))(x)\n","            x = LeakyReLU(alpha=0.25, name='disc_lr_2_2')(x)\n","            x = BatchNormalization(axis=channel_axis, name='disc_bn_2')(x, training=False)\n","\n","            x = Flatten(name='disc_flatten')(x)\n","            x = Dense(128, name='disc_dense_1')(x)\n","            x = LeakyReLU(alpha=0.25, name='disc_lr_final')(x)\n","            out = Dense(2, activation='softmax', name='disc_output')(x)\n","\n","            disc_model = Model(disc_init, out)\n","\n","            adam = optimizers.Adam(lr=1e-3)\n","            disc_model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['acc'])\n","            if load_weights: disc_model.load_weights(self.disc_weight_path)\n","\n","            for layer in disc_model.layers:\n","                layer.trainable = False\n","\n","            gen_out = gen_model(gen_init)\n","            disc_out = disc_model(gen_out)\n","\n","            full_model = Model(input=gen_init, output=disc_out)\n","\n","            for layer in full_model.layers[2].layers:\n","                layer.trainable = False\n","\n","            full_model.compile(optimizers.Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['acc'])\n","\n","            for layer in disc_model.layers:\n","                layer.trainable = True\n","\n","            self.model = full_model\n","            self.gen_model = gen_model\n","            self.disc_model = disc_model\n","\n","            # Setup evaluation function for validation\n","            self.evaluation_func = K.function([self.gen_model.layers[0].input],\n","                                              [self.gen_model.layers[-1].output])\n","\n","        else:\n","            self.model = gen_model\n","\n","        return self.model\n","\n","\n","    def set_trainable(self, model, value, prefix='gen'):\n","        for layer in model.layers:\n","            if 'model' in layer.name:\n","                model_index = -1\n","\n","                for deep_layer in model.layers[1].layers: # check generator layers\n","                    if prefix in deep_layer.name:\n","                        deep_layer.trainable = value\n","                        model_index = 1\n","\n","                for deep_layer in model.layers[2].layers: # check discriminator layers\n","                    if prefix in deep_layer.name:\n","                        deep_layer.trainable = value\n","                        model_index = 2\n","\n","                model.layers[model_index].trainable = value\n","                break\n","\n","            elif prefix in layer.name: # discriminator model\n","                layer.trainable = value\n","\n","\n","    def fit(self, nb_pretrain_samples=5000, batch_size=128, nb_epochs=100, disc_train_flip=0.1,\n","            save_history=True, history_fn=\"GAN SRCNN History.txt\"):\n","        samples_per_epoch = img_utils.image_count()\n","        meanaxis = (0, 2, 3) if K.image_dim_ordering() == 'th' else (0, 1, 2)\n","\n","        if self.model == None: self.create_model(mode='train', batch_size=batch_size)\n","\n","        if os.path.exists(self.gen_weight_path) and os.path.exists(self.disc_weight_path):\n","            self.gen_model.load_weights(self.gen_weight_path)\n","            self.disc_model.load_weights(self.disc_weight_path)\n","            print(\"Pre-trained Generator and Discriminator network weights loaded\")\n","        else:\n","            nb_train_samples = nb_pretrain_samples\n","\n","            print('Pre-training on %d images' % (nb_train_samples))\n","            batchX, batchY = next(img_utils.image_generator(train_path, scale_factor=self.scale_factor,\n","                                                       small_train_images=self.type_true_upscaling,\n","                                                       batch_size=nb_train_samples))\n","\n","            # [-1, 1] scale conversion from [0, 1]\n","            batchX = ((batchX * 255) - 127.5) / 127.5\n","            batchY = ((batchY * 255) - 127.5) / 127.5\n","\n","            print(\"Pre-training Generator network\")\n","            hist = self.gen_model.fit(batchX, batchY, batch_size, nb_epoch=200, verbose=2)\n","            print(\"Generator pretrain final PSNR : \", hist.history['PSNRLoss'][-1])\n","\n","            print(\"Pre-training Discriminator network\")\n","\n","            genX = self.gen_model.predict(batchX, batch_size=batch_size)\n","\n","            print('GenX Output mean (per channel) :', np.mean(genX, axis=meanaxis))\n","            print('BatchX mean (per channel) :', np.mean(batchX, axis=meanaxis))\n","\n","            X = np.concatenate((genX, batchX))\n","\n","            # Using soft and noisy labels\n","            if np.random.uniform() > disc_train_flip:\n","                # give correct classifications\n","                y = [0] * nb_train_samples + [1] * nb_train_samples\n","            else:\n","                # give wrong classifications (noisy labels)\n","                y = [1] * nb_train_samples + [0] * nb_train_samples\n","\n","            y = np.asarray(y, dtype=np.float32).reshape(-1, 1)\n","            y = to_categorical(y, nb_classes=2)\n","            y = img_utils.smooth_gan_labels(y)\n","\n","            hist = self.disc_model.fit(X, y, batch_size=batch_size,\n","                                       nb_epoch=1, verbose=0)\n","\n","            print('Discriminator History :', hist.history)\n","            print()\n","\n","        self.gen_model.save_weights(self.gen_weight_path, overwrite=True)\n","        self.disc_model.save_weights(self.disc_weight_path, overwrite=True)\n","\n","        iteration = 0\n","        save_index = 1\n","\n","        print(\"Training full model : %s\" % (self.__class__.__name__))\n","\n","        for i in range(nb_epochs):\n","            print(\"Epoch : %d\" % (i + 1))\n","            print()\n","\n","            for x, _ in img_utils.image_generator(train_path, scale_factor=self.scale_factor,\n","                                                  small_train_images=self.type_true_upscaling,  batch_size=batch_size):\n","                t1 = time.time()\n","\n","                x = ((x * 255) - 127.5) / 127.5\n","\n","                X_pred = self.gen_model.predict(x, batch_size)\n","\n","                print(\"Input batchX mean (per channel) :\", np.mean(x, axis=meanaxis))\n","                print(\"X_pred mean (per channel) :\", np.mean(X_pred, axis=meanaxis))\n","\n","                X = np.concatenate((X_pred, x))\n","                # Using soft and noisy labels\n","                if np.random.uniform() > disc_train_flip:\n","                    # give correct classifications\n","                    y_disc = [0] * nb_train_samples + [1] * nb_train_samples\n","                else:\n","                    # give wrong classifications (noisy labels)\n","                    y_disc = [1] * nb_train_samples + [0] * nb_train_samples\n","\n","                y_disc = np.asarray(y_disc, dtype=np.float32).reshape(-1, 1)\n","                y_disc = to_categorical(y_disc, nb_classes=2)\n","                y_disc = img_utils.smooth_gan_labels(y_disc)\n","\n","                hist = self.disc_model.fit(X, y_disc, verbose=0, batch_size=batch_size, nb_epoch=1)\n","\n","                discriminator_loss = hist.history['loss'][0]\n","                discriminator_acc = hist.history['acc'][0]\n","\n","                # Using soft labels\n","                y_model = [1] * nb_train_samples\n","                y_model = np.asarray(y_model, dtype=np.int).reshape(-1, 1)\n","                y_model = to_categorical(y_model, nb_classes=2)\n","                y_model = img_utils.smooth_gan_labels(y_model)\n","\n","                hist = self.model.fit(x, y_model, batch_size, nb_epoch=1, verbose=0)\n","                generative_loss = hist.history['loss'][0]\n","\n","                iteration += batch_size\n","                save_index += 1\n","\n","                t2 = time.time()\n","\n","                print(\"Iter : %d / %d | Time required : %0.2f seconds | Discriminator Loss / Acc : %0.6f / %0.3f | \"\n","                      \"Generative Loss : %0.6f\" % (iteration, samples_per_epoch, t2 - t1,\n","                                                   discriminator_loss, discriminator_acc, generative_loss))\n","\n","                # Validate at end of epoch\n","                if iteration >= samples_per_epoch:\n","                    print(\"Evaluating generator model...\")\n","                    # losses = self.gen_model.evaluate_generator(generator=img_utils.image_generator(train_path,\n","                    #                                            scale_factor=self.scale_factor,\n","                    #                                            small_train_images=self.type_true_upscaling,\n","                    #                                            batch_size=batch_size),\n","                    #                                            val_samples=samples_per_epoch)\n","                    #\n","                    # print('Generator Loss (PSNR):', losses[-1])\n","\n","                    self.evaluate('val_images/')\n","\n","                # Save weights every 100 iterations\n","                if save_index % 100 == 0:\n","                    print(\"Saving generator weights\")\n","                    self.gen_model.save_weights(self.weight_path, overwrite=True)\n","\n","                if iteration >= samples_per_epoch:\n","                    break\n","\n","            iteration = 0\n","            save_index = 1\n","\n","        return self.model\n","\n","    def evaluate(self, validation_dir):\n","        _evaluate(self, validation_dir, scale_pred=True)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"whgTOV8tpyb5","colab_type":"code","colab":{}},"source":["\n","class DistilledResNetSR(BaseSuperResolutionModel):\n","\n","    def __init__(self, scale_factor):\n","        super(DistilledResNetSR, self).__init__(\"DistilledResNetSR\", scale_factor)\n","\n","        # Treat this model as a denoising auto encoder\n","        # Force the fit, evaluate and upscale methods to take special care about image shape\n","        self.type_requires_divisible_shape = True\n","        self.uses_learning_phase = False\n","\n","        self.n = 32\n","        self.mode = 2\n","\n","        self.weight_path = \"weights/DistilledResNetSR %dX.h5\" % (self.scale_factor)\n","        self.type_true_upscaling = True\n","\n","    def create_model(self, height=32, width=32, channels=3, load_weights=False, batch_size=128):\n","        init =  super(DistilledResNetSR, self).create_model(height, width, channels, load_weights, batch_size)\n","\n","        x0 = Convolution2D(self.n, (3, 3), activation='relu', padding='same', name='student_sr_res_conv1')(init)\n","\n","        x = self._residual_block(x0, 1)\n","\n","        x = Add(name='student_residual')([x, x0])\n","        x = self._upscale_block(x, 1)\n","\n","        x = Convolution2D(3, (3, 3), activation=\"linear\", padding='same', name='student_sr_res_conv_final')(x)\n","\n","        model = Model(init, x)\n","        # dont compile yet\n","        if load_weights: model.load_weights(self.weight_path, by_name=True)\n","\n","        self.model = model\n","        return model\n","\n","    def _residual_block(self, ip, id):\n","        mode = False if self.mode == 2 else None\n","        channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n","        init = ip\n","\n","        x = Convolution2D(self.n, (3, 3), activation='linear', padding='same',\n","                          name='student_sr_res_conv_' + str(id) + '_1')(ip)\n","        x = BatchNormalization(axis=channel_axis, name=\"student_sr_res_batchnorm_\" + str(id) + \"_1\")(x, training=mode)\n","        x = Activation('relu', name=\"student_sr_res_activation_\" + str(id) + \"_1\")(x)\n","\n","        x = Convolution2D(self.n, (3, 3), activation='linear', padding='same',\n","                          name='student_sr_res_conv_' + str(id) + '_2')(x)\n","        x = BatchNormalization(axis=channel_axis, name=\"student_sr_res_batchnorm_\" + str(id) + \"_2\")(x, training=mode)\n","\n","        m = Add(name=\"student_sr_res_merge_\" + str(id))([x, init])\n","\n","        return m\n","\n","    def _upscale_block(self, ip, id):\n","        init = ip\n","\n","        channel_dim = 1 if K.image_data_format() == 'channels_first' else -1\n","        channels = init._keras_shape[channel_dim]\n","\n","        x = UpSampling2D(name='student_upsampling_%d' % id)(init)\n","        x = Convolution2D(self.n * 2, (3, 3), activation=\"relu\", padding='same', name='student_sr_res_filter1_%d' % id)(x)\n","\n","        return x\n","\n","    def fit(self, batch_size=128, nb_epochs=100, save_history=True, history_fn=\"Distilled ResNetSR History.txt\"):\n","        super(DistilledResNetSR, self).fit(batch_size, nb_epochs, save_history, history_fn)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SmvGZVghOQUw","colab_type":"code","colab":{}},"source":["\n","class NonLocalResNetSR(BaseSuperResolutionModel):\n","\n","    def __init__(self, scale_factor):\n","        super(NonLocalResNetSR, self).__init__(\"NonLocalResNetSR\", scale_factor)\n","\n","        # Treat this model as a denoising auto encoder\n","        # Force the fit, evaluate and upscale methods to take special care about image shape\n","        self.type_requires_divisible_shape = True\n","        self.uses_learning_phase = False\n","\n","        self.n = 32\n","        self.mode = 2\n","\n","        self.weight_path = \"weights/NonLocalResNetSR %dX.h5\" % (self.scale_factor)\n","        self.type_true_upscaling = True\n","\n","    def create_model(self, height=32, width=32, channels=3, load_weights=False, batch_size=128):\n","        init =  super(NonLocalResNetSR, self).create_model(height, width, channels, load_weights, batch_size)\n","\n","        x0 = Convolution2D(self.n, (3, 3), activation='relu', padding='same', name='sr_res_conv1')(init)\n","        x0 = non_local_block(x0)\n","\n","        x = self._residual_block(x0, 1)\n","\n","        nb_residual = 5\n","        for i in range(nb_residual):\n","            x = self._residual_block(x, i + 2)\n","\n","        x = non_local_block(x, computation_compression=2)\n","        x = Add()([x, x0])\n","\n","        x = self._upscale_block(x, 1)\n","\n","        x = Convolution2D(3, (3, 3), activation=\"linear\", padding='same', name='sr_res_conv_final')(x)\n","\n","        model = Model(init, x)\n","\n","        adam = optimizers.Adam(lr=1e-3)\n","        model.compile(optimizer=adam, loss='mse', metrics=[PSNRLoss])\n","        if load_weights: model.load_weights(self.weight_path, by_name=True)\n","\n","        self.model = model\n","        return model\n","\n","    def _residual_block(self, ip, id):\n","        mode = False if self.mode == 2 else None\n","        channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n","        init = ip\n","\n","        x = Convolution2D(self.n, (3, 3), activation='linear', padding='same',\n","                          name='sr_res_conv_' + str(id) + '_1')(ip)\n","        x = BatchNormalization(axis=channel_axis, name=\"sr_res_batchnorm_\" + str(id) + \"_1\")(x, training=mode)\n","        x = Activation('relu', name=\"sr_res_activation_\" + str(id) + \"_1\")(x)\n","\n","        x = Convolution2D(self.n, (3, 3), activation='linear', padding='same',\n","                          name='sr_res_conv_' + str(id) + '_2')(x)\n","        x = BatchNormalization(axis=channel_axis, name=\"sr_res_batchnorm_\" + str(id) + \"_2\")(x, training=mode)\n","\n","        m = Add(name=\"sr_res_merge_\" + str(id))([x, init])\n","\n","        return m\n","\n","    def _upscale_block(self, ip, id):\n","        init = ip\n","\n","        channel_dim = 1 if K.image_data_format() == 'channels_first' else -1\n","\n","        x = UpSampling2D()(init)\n","        x = Convolution2D(self.n, (3, 3), activation=\"relu\", padding='same', name='sr_res_filter1_%d' % id)(x)\n","\n","        return x\n","\n","    def fit(self, batch_size=128, nb_epochs=100, save_history=True, history_fn=\"Non Local ResNetSR History.txt\"):\n","        super(NonLocalResNetSR, self).fit(batch_size, nb_epochs, save_history, history_fn)"],"execution_count":0,"outputs":[]}]}