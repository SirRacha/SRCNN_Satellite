{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SRCNN1_image_util.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"s90E5-DbffrM","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"tPqasU9ydp5o","colab_type":"code","colab":{}},"source":["## Use this method if mapping the filepath wont work ##\n","#!unzip input_images.zip\n","\n","# option 2 for images\n","#!unzip -uq \"/content/drive/My Drive/PATH_TO_ZIP\" -d \"/content/drive/My Drive/Colab Notebooks/Image-Super-Resolution/input_images.zip\"\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5ctWkYvGBQg7","colab_type":"code","outputId":"e09a15c9-fd98-4fcb-d686-2cb29d9b7a96","executionInfo":{"status":"ok","timestamp":1566249629452,"user_tz":300,"elapsed":3345,"user":{"displayName":"Chris H","photoUrl":"https://lh5.googleusercontent.com/-nSgQPDHt3xI/AAAAAAAAAAI/AAAAAAAAAQQ/2R6OZokGpgg/s64/photo.jpg","userId":"06776436809075546973"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["!pip install -U scipy==1.2.0"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already up-to-date: scipy==1.2.0 in /usr/local/lib/python3.6/dist-packages (1.2.0)\n","Requirement already satisfied, skipping upgrade: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.2.0) (1.16.4)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hajwzNN8BfGV","colab_type":"code","outputId":"91299473-7c49-42e5-dcd3-40a55a4d9b21","executionInfo":{"status":"ok","timestamp":1566249634772,"user_tz":300,"elapsed":446,"user":{"displayName":"Chris H","photoUrl":"https://lh5.googleusercontent.com/-nSgQPDHt3xI/AAAAAAAAAAI/AAAAAAAAAQQ/2R6OZokGpgg/s64/photo.jpg","userId":"06776436809075546973"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","root_dir = \"/content/drive/My Drive/\"\n","\n","## os library is used to assign filepath locations too\n","import os\n","os.chdir('./drive/My Drive/Colab Notebooks/Image-Super-Resolution')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2hV4_G_8RdHD","colab_type":"code","outputId":"772bf2ae-25c0-4b6a-9bbf-385b0054470a","executionInfo":{"status":"ok","timestamp":1566249657501,"user_tz":300,"elapsed":1757,"user":{"displayName":"Chris H","photoUrl":"https://lh5.googleusercontent.com/-nSgQPDHt3xI/AAAAAAAAAAI/AAAAAAAAAQQ/2R6OZokGpgg/s64/photo.jpg","userId":"06776436809075546973"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["!ls\n","#!cd drive/My Drive/Colab Notebooks/Image-Super-Resolution"],"execution_count":0,"outputs":[{"output_type":"stream","text":[" advanced.py\t       input_images\t  results\n"," architectures\t       input_images.zip   SRCNN1_image_util.ipynb\n","'Copy of main.ipynb'   main.py\t\t  SRCNN1_Notes.ipynb\n"," Dataset\t       models.py\t  tests.py\n"," distill_network.py    output_images\t  val_images\n"," Framework-Update.md   __pycache__\t  weights\n"," img_utils.py\t       README.md\t  windows_helper\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EZPT2bu7Hmo4","colab_type":"code","colab":{}},"source":["!pwd"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yDWfmtnaBH1U","colab_type":"code","outputId":"15bfc005-0a45-4c2e-8f9d-abdbcc7d6feb","executionInfo":{"status":"ok","timestamp":1566249665341,"user_tz":300,"elapsed":1985,"user":{"displayName":"Chris H","photoUrl":"https://lh5.googleusercontent.com/-nSgQPDHt3xI/AAAAAAAAAAI/AAAAAAAAAQQ/2R6OZokGpgg/s64/photo.jpg","userId":"06776436809075546973"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import numpy as np\n","from scipy.misc import imsave, imread, imresize\n","from sklearn.feature_extraction.image import reconstruct_from_patches_2d, extract_patches_2d\n","from scipy.ndimage.filters import gaussian_filter\n","\n","from keras import backend as K\n","\n","import os\n","import time\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"SBJgRCCjC2h3","colab_type":"code","colab":{}},"source":["'''\n","_image_scale_multiplier is a special variable which is used to alter image size.\n","\n","The default image size is 32x32. If a true upscaling model is used, then the input image size is 16x16,\n","which not offer adequate training samples.\n","'''\n","_image_scale_multiplier = 1\n","\n","img_size = 128 * _image_scale_multiplier\n","stride = 64 * _image_scale_multiplier\n","\n","assert (img_size ** 2) % (stride ** 2) == 0, \"Number of images generated from strided subsample of the image needs to be \\n\" \\\n","                                             \"a positive integer. Change stride such that : \\n\" \\\n","                                             \"(img_size ** 2) / (stride ** 2) is a positive integer.\"\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IXDuAJUbC2mS","colab_type":"code","colab":{}},"source":["#input_path = r\"D:\\Yue\\Documents\\Datasets\\train2014\\train2014\\\\\" # r\"input_images/\"\n","validation_path = r\"val_images/\"\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hwWDRSA_C8LN","colab_type":"code","colab":{}},"source":["\n","validation_set5_path = validation_path + r\"set5/\"\n","validation_set14_path = validation_path + r\"set14/\"\n","\n","base_dataset_dir = r\"/content/drive/My Drive/Colab Notebooks/Image-Super-Resolution\" + r\"/Dataset/\"\n","\n","output_path = base_dataset_dir + \"train_images/train/\"\n","validation_output_path = base_dataset_dir + r\"train_images/validation/\"\n","\n","if not os.path.exists(output_path):\n","    os.makedirs(output_path)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MSP-PRfFC8Q4","colab_type":"code","colab":{}},"source":["\n","def transform_images_temp(directory, output_directory, scaling_factor=2, max_nb_images=-1, true_upscale=False,\n","                          id_advance=0):\n","    index = 1\n","\n","    if not os.path.exists(output_directory + \"X/\"):\n","        os.makedirs(output_directory + \"X/\")\n","\n","    if not os.path.exists(output_directory + \"y/\"):\n","        os.makedirs(output_directory + \"y/\")\n","\n","    # For each image in input_images directory\n","    nb_images = len([name for name in os.listdir(directory)])\n","\n","    if max_nb_images != -1:\n","        print(\"Transforming %d images.\" % max_nb_images)\n","    else:\n","        assert max_nb_images <= nb_images, \"Max number of images must be less than number of images in path\"\n","        print(\"Transforming %d images.\" % (nb_images))\n","\n","    if nb_images == 0:\n","        print(\"Extract the training images or images from imageset_91.zip (found in the releases of the project) \"\n","              \"into a directory with the name 'input_images'\")\n","        print(\"Extract the validation images or images from set5_validation.zip (found in the releases of the project) \"\n","              \"into a directory with the name 'val_images'\")\n","        exit()\n","\n","    for file in os.listdir(directory):\n","        img = imread(directory + file, mode='RGB')\n","\n","        # Resize to 256 x 256\n","        img = imresize(img, (img_size, img_size))\n","\n","        # Create patches\n","        hr_patch_size = 64\n","        lr_patch_size = 32\n","        nb_hr_images = (img_size ** 2) // (stride ** 2)\n","\n","        hr_samples = np.empty((nb_hr_images, hr_patch_size, hr_patch_size, 3))\n","\n","        image_subsample_iterator = subimage_generator(img, stride, hr_patch_size, nb_hr_images)\n","\n","        stride_range = np.sqrt(nb_hr_images).astype(int)\n","\n","        i = 0\n","        for j in range(stride_range):\n","            for k in range(stride_range):\n","                hr_samples[i, :, :, :] = next(image_subsample_iterator)\n","                i += 1\n","\n","\n","        t1 = time.time()\n","        # Create nb_hr_images 'X' and 'Y' sub-images of size hr_patch_size for each patch\n","        for i in range(nb_hr_images):\n","            ip = hr_samples[i]\n","            # Save ground truth image X\n","            imsave(output_directory + \"/y/\" + \"%d_%d.png\" % (index + id_advance, i + 1), ip)\n","\n","            # Apply Gaussian Blur to Y\n","            #op = gaussian_filter(ip, sigma=0.5)\n","\n","            # Subsample by scaling factor to Y\n","            op = imresize(ip, (lr_patch_size, lr_patch_size), interp='bicubic')\n","\n","            if not true_upscale:\n","                # Upscale by scaling factor to Y\n","                op = imresize(op, (hr_patch_size, hr_patch_size), interp='bicubic')\n","\n","            # Save Y\n","            imsave(output_directory + \"/X/\" + \"%d_%d.png\" % (index + id_advance, id_advance + i + 1), op)\n","\n","        print(\"Finished image %d in time %0.2f seconds. (%s)\" % (index + id_advance, time.time() - t1, file))\n","        index += 1\n","\n","        if max_nb_images > 0 and index >= max_nb_images:\n","            print(\"Transformed maximum number of images. \")\n","            break\n","\n","    print(\"Images transformed. Saved at directory : %s\" % (output_directory))\n","\n","\n","def image_count():\n","    return len([name for name in os.listdir(output_path + \"X/\")])\n","\n","\n","def val_image_count():\n","    return len([name for name in os.listdir(validation_output_path + \"X/\")])\n","\n","\n","def subimage_generator(img, stride, patch_size, nb_hr_images):\n","    for _ in range(nb_hr_images):\n","        for x in range(0, img_size, stride):\n","            for y in range(0, img_size, stride):\n","                subimage = img[x : x + patch_size, y : y + patch_size, :]\n","\n","                yield subimage\n","\n","\n","def make_patches(x, scale, patch_size, upscale=True, verbose=1):\n","    '''x shape: (num_channels, rows, cols)'''\n","    height, width = x.shape[:2]\n","    if upscale: x = imresize(x, (height * scale, width * scale))\n","    patches = extract_patches_2d(x, (patch_size, patch_size))\n","    return patches\n","\n","\n","def combine_patches(in_patches, out_shape, scale):\n","    '''Reconstruct an image from these `patches`'''\n","    recon = reconstruct_from_patches_2d(in_patches, out_shape)\n","    return recon\n","\n","def image_generator(directory, scale_factor=2, target_shape=None, channels=3, small_train_images=False, shuffle=True,\n","                    batch_size=32, nb_inputs=1, seed=None):\n","    if not target_shape:\n","        if small_train_images:\n","            if K.image_dim_ordering() == \"th\":\n","                image_shape = (channels, 16 * _image_scale_multiplier, 16 * _image_scale_multiplier)\n","                y_image_shape = (channels, 16 * scale_factor * _image_scale_multiplier,\n","                                 16 * scale_factor * _image_scale_multiplier)\n","            else:\n","                # image_shape = (16 * _image_scale_multiplier, 16 * _image_scale_multiplier, channels)\n","                # y_image_shape = (16 * scale_factor * _image_scale_multiplier,\n","                #                  16 * scale_factor * _image_scale_multiplier, channels)\n","                image_shape = (32 * _image_scale_multiplier, 32 * _image_scale_multiplier, channels)\n","                y_image_shape = (32 * scale_factor * _image_scale_multiplier,\n","                                 32 * scale_factor * _image_scale_multiplier, channels)\n","        else:\n","            if K.image_dim_ordering() == \"th\":\n","                image_shape = (channels, 32 * scale_factor * _image_scale_multiplier, 32 * scale_factor * _image_scale_multiplier)\n","                y_image_shape = image_shape\n","            else:\n","                image_shape = (32 * scale_factor * _image_scale_multiplier, 32 * scale_factor * _image_scale_multiplier,\n","                               channels)\n","                y_image_shape = image_shape\n","    else:\n","        if small_train_images:\n","            if K.image_dim_ordering() == \"th\":\n","                y_image_shape = (3,) + target_shape\n","\n","                target_shape = (target_shape[0] * _image_scale_multiplier // scale_factor,\n","                                target_shape[1] * _image_scale_multiplier // scale_factor)\n","                image_shape = (3,) + target_shape\n","            else:\n","                y_image_shape = target_shape + (channels,)\n","\n","                target_shape = (target_shape[0] * _image_scale_multiplier // scale_factor,\n","                                target_shape[1] * _image_scale_multiplier // scale_factor)\n","                image_shape = target_shape + (channels,)\n","        else:\n","            if K.image_dim_ordering() == \"th\":\n","                image_shape = (channels,) + target_shape\n","                y_image_shape = image_shape\n","            else:\n","                image_shape = target_shape + (channels,)\n","                y_image_shape = image_shape\n","\n","    file_names = [f for f in sorted(os.listdir(directory + \"X/\"))]\n","    X_filenames = [os.path.join(directory, \"X\", f) for f in file_names]\n","    y_filenames = [os.path.join(directory, \"y\", f) for f in file_names]\n","\n","    nb_images = len(file_names)\n","    print(\"Found %d images.\" % nb_images)\n","\n","    index_generator = _index_generator(nb_images, batch_size, shuffle, seed)\n","\n","    while 1:\n","        index_array, current_index, current_batch_size = next(index_generator)\n","\n","        batch_x = np.zeros((current_batch_size,) + image_shape)\n","        batch_y = np.zeros((current_batch_size,) + y_image_shape)\n","\n","        for i, j in enumerate(index_array):\n","            x_fn = X_filenames[j]\n","            img = imread(x_fn, mode='RGB')\n","            if small_train_images:\n","                img = imresize(img, (32 * _image_scale_multiplier, 32 * _image_scale_multiplier))\n","            img = img.astype('float32') / 255.\n","\n","            if K.image_dim_ordering() == \"th\":\n","                batch_x[i] = img.transpose((2, 0, 1))\n","            else:\n","                batch_x[i] = img\n","\n","            y_fn = y_filenames[j]\n","            img = imread(y_fn, mode=\"RGB\")\n","            img = img.astype('float32') / 255.\n","\n","            if K.image_dim_ordering() == \"th\":\n","                batch_y[i] = img.transpose((2, 0, 1))\n","            else:\n","                batch_y[i] = img\n","\n","        if nb_inputs == 1:\n","            yield (batch_x, batch_y)\n","        else:\n","            batch_x = [batch_x for i in range(nb_inputs)]\n","            yield batch_x, batch_y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dYJIvu3wC8OH","colab_type":"code","colab":{}},"source":["def _index_generator(N, batch_size=32, shuffle=True, seed=None):\n","    batch_index = 0\n","    total_batches_seen = 0\n","\n","    while 1:\n","        if seed is not None:\n","            np.random.seed(seed + total_batches_seen)\n","\n","        if batch_index == 0:\n","            index_array = np.arange(N)\n","            if shuffle:\n","                index_array = np.random.permutation(N)\n","\n","        current_index = (batch_index * batch_size) % N\n","\n","        if N >= current_index + batch_size:\n","            current_batch_size = batch_size\n","            batch_index += 1\n","        else:\n","            current_batch_size = N - current_index\n","            batch_index = 0\n","        total_batches_seen += 1\n","\n","        yield (index_array[current_index: current_index + current_batch_size],\n","               current_index, current_batch_size)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2DkW-YOYD5xq","colab_type":"code","colab":{}},"source":["def smooth_gan_labels(y):\n","    assert len(y.shape) == 2, \"Needs to be a binary class\"\n","    y = np.asarray(y, dtype='int')\n","    Y = np.zeros(y.shape, dtype='float32')\n","\n","    for i in range(y.shape[0]):\n","        for j in range(y.shape[1]):\n","            if y[i, j] == 0:\n","                Y[i, j] = np.random.uniform(0.0, 0.3)\n","            else:\n","                Y[i, j] = np.random.uniform(0.7, 1.2)\n","\n","    return Y\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"keInINbwD5t-","colab_type":"code","outputId":"8bf7783d-07a0-4299-f7d2-2fd6bb984dfb","executionInfo":{"status":"ok","timestamp":1566249686193,"user_tz":300,"elapsed":6959,"user":{"displayName":"Chris H","photoUrl":"https://lh5.googleusercontent.com/-nSgQPDHt3xI/AAAAAAAAAAI/AAAAAAAAAQQ/2R6OZokGpgg/s64/photo.jpg","userId":"06776436809075546973"}},"colab":{"base_uri":"https://localhost:8080/","height":564}},"source":["if __name__ == \"__main__\":\n","    # Transform the images once, then run the main code to scale images\n","\n","    # Change scaling factor to increase the scaling factor\n","    scaling_factor = 2\n","\n","    # Set true_upscale to True to generate smaller training images that will then be true upscaled.\n","    # Leave as false to create same size input and output images\n","    true_upscale = True\n","\n","    # transform_images_temp(input_path, output_path, scaling_factor=scaling_factor, max_nb_images=-1,\n","    #                  true_upscale=true_upscale)\n","    transform_images_temp(validation_set14_path, validation_output_path, scaling_factor=scaling_factor, max_nb_images=-1,\n","                     true_upscale=true_upscale)\n","    # transform_images_temp(validation_set14_path, validation_output_path, scaling_factor=scaling_factor, max_nb_images=-1,\n","    #                       true_upscale=true_upscale)\n","    pass\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Transforming 14 images.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: DeprecationWarning: `imread` is deprecated!\n","`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n","Use ``imageio.imread`` instead.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: DeprecationWarning: `imresize` is deprecated!\n","`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n","Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: `imsave` is deprecated!\n","`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n","Use ``imageio.imwrite`` instead.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:63: DeprecationWarning: `imresize` is deprecated!\n","`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n","Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: DeprecationWarning: `imsave` is deprecated!\n","`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n","Use ``imageio.imwrite`` instead.\n"],"name":"stderr"},{"output_type":"stream","text":["Finished image 1 in time 0.80 seconds. (baboon.bmp)\n","Finished image 2 in time 0.06 seconds. (barbara.bmp)\n","Finished image 3 in time 0.03 seconds. (bridge.bmp)\n","Finished image 4 in time 0.05 seconds. (coastguard.bmp)\n","Finished image 5 in time 0.03 seconds. (comic.bmp)\n","Finished image 6 in time 0.05 seconds. (face.bmp)\n","Finished image 7 in time 0.04 seconds. (flowers.bmp)\n","Finished image 8 in time 0.03 seconds. (foreman.bmp)\n","Finished image 9 in time 0.06 seconds. (lenna.bmp)\n","Finished image 10 in time 0.03 seconds. (man.bmp)\n","Finished image 11 in time 0.06 seconds. (monarch.bmp)\n","Finished image 12 in time 0.04 seconds. (pepper.bmp)\n","Finished image 13 in time 0.06 seconds. (ppt3.bmp)\n","Finished image 14 in time 0.04 seconds. (zebra.bmp)\n","Images transformed. Saved at directory : /content/drive/My Drive/Colab Notebooks/Image-Super-Resolution/Dataset/train_images/validation/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9KVuUy5VwXhj","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}